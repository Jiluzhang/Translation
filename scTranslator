# scTranslator: https://github.com/TencentAILabHealthcare/scTranslator
# performer: https://github.com/lucidrains/performer-pytorch
# transformer test: https://github.com/rogershijin/GANOLI

######################################### Installation #########################################
conda create -n scTranslator python=3.8.13
pip install scipy==1.9.1 numpy==1.21.5 pandas==1.5.1 scikit-learn==1.1.2 scanpy==1.9.1  # numba 0.58.1 requires numpy<1.27, >=1.22 (1.24.4)
pip install matplotlib==3.6.3  # import scanpy bug: TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases
pip install einops local_attention
conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch  # debug: RuntimeError: CUDA error: no kernel image is available for execution on the device
wget -c https://codeload.github.com/TencentAILabHealthcare/scTranslator/zip/refs/heads/main


######################################### run model use provided data (RNA -> Protein) #########################################
scp -P 6122 GSM2685244_protein_3_PBMCs_matrix_mapped.h5ad GSM2685244_mRNA_3_PBMCs_matrix_mapped.h5ad jiluzhang@10.11.41.108:/fs/home/jiluzhang/scTranslator/dataset/test/dataset2
scp -P 6122 stage2_single-cell_scTranslator.pt jiluzhang@10.11.41.108:/fs/home/jiluzhang/scTranslator/checkpoint
python code/stage3_inference_without_finetune.py \
--pretrain_checkpoint='checkpoint/stage2_single-cell_scTranslator.pt' \
--RNA_path='dataset/test/dataset2/GSM2685244_mRNA_3_PBMCs_matrix_mapped.h5ad' \
--Pro_path='dataset/test/dataset2/GSM2685244_protein_3_PBMCs_matrix_mapped.h5ad'

#Total number of origin RNA genes:  21005
#Total number of origin proteins:  44
#Total number of origin cells:  4330
## of NAN in X 0
## of NAN in X 0
#load data ended
#----------------------------------------
#single cell 20000 RNA To 1000 Protein on dataset/new_data-without_fine-tune
#Overall performance in repeat_1 costTime: 168.5123s
#Test Set: AVG mse 0.0408, AVG ccc 0.3924

#real	2m51.998s
#user	87m39.110s
#sys	1m50.236s

# output files
# args1.txt & performance_log.csv

## distributed training: https://zhuanlan.zhihu.com/p/76638962
python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 2 --master_addr '10.11.41.108' --master_port 6123 \
code/stage3_fine-tune.py  --epoch=1 --frac_finetune_test=0.1 --fix_set \
--pretrain_checkpoint='checkpoint/stage2_single-cell_scTranslator.pt' \
--RNA_path='dataset/test/dataset2/GSM2685244_mRNA_3_PBMCs_matrix_mapped.h5ad' \
--Pro_path='dataset/test/dataset2/GSM2685244_protein_3_PBMCs_matrix_mapped.h5ad'

# assign gpu
# add 'os.environ["CUDA_VISIBLE_DEVICES"]="0,1"' to 'stage3_fine-tune.py'

# nnodes:当前job包含多少个节点(单机多卡nnodes=1)
# node_rank: 当前节点的优先级
# nproc_per_node: 当前主机创建的进程数（一般设定为当前主机的GPU数量）
# master_addr: master节点的ip
# master_port: master节点的port


############################## Modify the raw scTranslator model ##############################
# performer_enc_dec.py  'self.pos_emb = nn.Embedding(85500,dim,padding_idx=0)'  85500 -> 300000
# mask 'model = torch.load(args.pretrain_checkpoint)' in 'stage3_fine-tune.py'
# utils.py: 'loss = F.mse_loss(y_hat[pro_mask], y[pro_mask])' -> 'loss = F.cross_entropy(y_hat[pro_mask], y[pro_mask])' (line 43)
#            'test_loss += F.mse_loss(y_hat[pro_mask], y[pro_mask]).item()' -> 'test_loss += F.cross_entropy(y_hat[pro_mask], y[pro_mask]).item()' (line 80)
#            'train_ccc += loss2(y_hat[pro_mask], y[pro_mask]).item()' -> 'auroc = AUROC(task='binary'); train_ccc += auroc(y_hat[pro_mask], y[pro_mask]).item()'  (line 46)
#            'test_ccc += loss2(y_hat[pro_mask], y[pro_mask]).item()' -> 'auroc = AUROC(task='binary'); test_ccc += auroc(y_hat[pro_mask], y[pro_mask]).item()'    (line 81)
#         add 'from torchmetrics import AUROC'  (line 7)
#         'loss' -> 'ce_loss' & 'ccc' -> 'auroc'
#         add 'print('Testing set: Average ce_loss: {:.4f}, Average auroc: {:.4f}'.format(test_loss, test_ccc), flush=True)' to line 84

# stage3_fine-tune.py: 'mse' -> 'cross entropy' & 'ccc' -> 'auroc' (line 234)
#                      'mse' -> 'cross entropy' & 'ccc' -> 'auroc' (line 235)
#                      add 'test_loss, test_ccc = test(model, device, test_loader)' to line 201

# performer_enc_dec.py
# add 'enc_kwargs['max_seq_len']=128' to line 200
# add 'self.d_r = nn.Linear(50000, 128)'  to line 206
# 'seq_in' -> 'self.d_r(seq_in)'  &  'seq_inID' -> seq_inID[:, :128]
# add 'dec_kwargs['max_seq_len']=256' to line 205
# add 'self.d_r_2 = nn.Linear(256, 1000)' to line 206
# 'self.dec(seq_out, seq_outID, **dec_kwargs)' -> 'self.d_r_2(self.dec(seq_out, seq_outID[:, :256], **dec_kwargs))'  line 212

# utils.py
# add '[:, :128]' to line 29
# add '[:, :128]' to line 67
# add '[:, :256]' to line 35
# add '[:, :256]' to line 73
# add 'from tqdm import tqdm' to line 7
# 'enumerate(train_loader)' -> 'enumerate(tqdm(train_loader, desc='Training', ncols=100))' line 25
# 'test_loader' -> 'tqdm(test_loader, desc='Testing', ncols=100)' line 63

# pip install torchmetrics
# pip install torcheval
...


############################## Process ATAC peaks and genes ##############################
# cCREs: wget -c https://downloads.wenglab.org/V3/GRCh38-cCREs.bed
awk '{if($1!="chrX" && $1!="chrY") print($1 "\t" $2 "\t" $3)}' GRCh38-cCREs.bed > human_cCREs.bed  # 1,036,913

# conda install -c bioconda bedtools
# pip install pybedtools

# human gtf file: wget -c https://ftp.ensembl.org/pub/release-110/gtf/homo_sapiens/Homo_sapiens.GRCh38.110.chr.gtf.gz
# gunzip Homo_sapiens.GRCh38.110.chr.gtf.gz
## centered by gene_id
grep gene_name Homo_sapiens.GRCh38.110.chr.gtf | awk -F "\t" '{if($1!="X" && $1!="Y" && $1!="MT" && $3=="gene") print$9}' | awk '{print $2}' | sed 's/"//g' | sed 's/;//g' > gene_id.txt
grep gene_name Homo_sapiens.GRCh38.110.chr.gtf | awk -F "\t" '{if($1!="X" && $1!="Y" && $1!="MT" && $3=="gene") print$9}' | awk '{print $6}' | sed 's/"//g' | sed 's/;//g' > gene_name.txt
paste gene_id.txt gene_name.txt > human_genes.txt  # 39884
rm gene_id.txt gene_name.txt

## cetered by gene_name
grep gene_name Homo_sapiens.GRCh38.110.chr.gtf | awk -F "\t" '{if($1!="X" && $1!="Y" && $1!="MT" && $3=="gene") print$9}' | awk '{print $2}' | sed 's/"//g' | sed 's/;//g' > gene_id.txt
grep gene_name Homo_sapiens.GRCh38.110.chr.gtf | awk -F "\t" '{if($1!="X" && $1!="Y" && $1!="MT" && $3=="gene") print$9}' | awk '{print $6}' | sed 's/"//g' | sed 's/;//g' > gene_name.txt
paste gene_id.txt gene_name.txt | sort > human_genes_raw.txt
rm gene_id.txt gene_name.txt

import pandas as pd
dat = pd.read_table('human_genes_raw.txt', names=['gene_id', 'gene_name'])
gene_cnt = dat.groupby('gene_name').agg('count').reset_index()
gene_cnt.columns = ['gene_name', 'cnt']
out = pd.merge(dat, gene_cnt)
out = out[out['cnt']==1][['gene_id', 'gene_name']]
out.to_csv('human_genes.txt', sep='\t', index=False, header=False)  # 38244

rm human_genes_raw.txt




####################################### Train model ##########################################
time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/stage3_fine-tune.py --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=50 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 39884 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_dm_1000.h5ad' --Pro_path='rna2atac/atac_train_dm_1000.h5ad'


time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/stage3_fine-tune.py --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=50 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_dm_1000.h5ad' --Pro_path='rna2atac/atac_train_dm_1000.h5ad'  # update gene number

## 5000 cells are too much for scATAC-seq data
time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/stage3_fine-tune.py --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=50 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_dm_5000.h5ad' --Pro_path='rna2atac/atac_train_dm_5000.h5ad'

time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/conti_train.py --pretrain_checkpoint='scM2M_with_weight/dm_1000/epoch_30.pt' --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=50 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_dm_1000_2000.h5ad' --Pro_path='rna2atac/atac_train_dm_1000_2000.h5ad'


time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/conti_train.py --pretrain_checkpoint='scM2M_with_weight/dm_1000/epoch_30.pt' --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=50 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_hsr_1000.h5ad' --Pro_path='rna2atac/atac_train_hsr_1000.h5ad'


######################################################
time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/stage3_fine-tune.py --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=10 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_sci_car_1000.h5ad' --Pro_path='rna2atac/atac_train_sci_car_1000.h5ad'


time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/stage3_fine-tune.py --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=10 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='datasets/rna_train_five_tissues_1000.h5ad' --Pro_path='datasets/atac_train_five_tissues_1000.h5ad'


time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/conti_train.py --pretrain_checkpoint='scM2M_with_weight/dm_1000_hsr_1000_mix_1/epoch_10.pt' --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=50 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_dm_500_hsr_500_2.h5ad' --Pro_path='rna2atac/atac_train_dm_500_hsr_500_2.h5ad'

######################################################


time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/conti_train.py --pretrain_checkpoint='scM2M_with_weight/dm_1000/epoch_30.pt' --batch_size 64 --test_batch_size 64 --lr 2e-4 --translator_depth 1 --epoch=50 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_dm_1000_2000.h5ad' --Pro_path='rna2atac/atac_train_dm_1000_2000.h5ad'  # reduce learning rate





## training loss
grep -o -P 'Training set: Average wbce_loss: .{6}' scTranslator_weight_50_cell_1000.log | sed 's/Training set: Average wbce_loss: //g'
## training auprc
grep "Training set" scTranslator_weight_50_cell_1000.log | grep -o -P "Average auprc: .{6}" | sed 's/Average auprc: //g'
## training auroc
grep "Training set" scTranslator_weight_50_cell_1000.log | grep -o -P "Average auroc: .{6}" | sed 's/Average auroc: //g'
## testing loss
grep -o -P 'Testing set: Average bce_loss: .{6}' scTranslator_weight_50_cell_1000.log | sed 's/Testing set: Average bce_loss: //g'
## testing auprc
grep "Testing set" scTranslator_weight_50_cell_1000.log | grep -o -P "Average auprc: .{6}" | sed 's/Average auprc: //g'
## testing auroc
grep "Testing set" scTranslator_weight_50_cell_1000.log | grep -o -P "Average auroc: .{6}" | sed 's/Average auroc: //g'
# -o: only show the matching part


####################################### Prediction ##########################################
time python code/predict.py --pretrain_checkpoint='scM2M_with_weight/epoch_30.pt' \
--RNA_path='rna2atac/rna_test_dm_100.h5ad' --test_batch_size 64 --seed 0 --enc_max_seq_len 39884 --dec_max_seq_len 1036913 

time python code/predict.py --pretrain_checkpoint='scM2M_with_weight/epoch_30.pt' \
--RNA_path='rna2atac/rna_test_pbmc_100.h5ad' --test_batch_size 64 --seed 0 --enc_max_seq_len 39884 --dec_max_seq_len 1036913 

time python code/predict.py --pretrain_checkpoint='scM2M_with_weight/epoch_10.pt' \
--RNA_path='rna2atac/rna_test_dm_100.h5ad' --test_batch_size 64 --seed 0 --enc_max_seq_len 38244 --dec_max_seq_len 1036913 

time python code/predict.py --pretrain_checkpoint='scM2M_with_weight/epoch_10.pt' \
--RNA_path='rna2atac/rna_test_pbmc_100.h5ad' --test_batch_size 64 --seed 0 --enc_max_seq_len 38244 --dec_max_seq_len 1036913 


## obtain attention matrix
python code/attention_matrix.py --pretrain_checkpoint='scM2M_with_weight/dm_1000_hsr_1000_mix_1/epoch_10.pt' \
--RNA_path='rna2atac/rna_test_dm_100.h5ad' --Pro_path='rna2atac/atac_test_dm_100.h5ad' \
--test_batch_size 1 --seed 0 --enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1


model = scPerformerEncDec(
        dim=16,
        translator_depth=1,
        initial_dropout=0.1,
        enc_depth=1,
        enc_heads=1,
        enc_max_seq_len=38244,
        dec_depth=1,
        dec_heads=1,
        dec_max_seq_len=1036913
        )



## plot attention matrix heatmap
import scanpy as sc
import seaborn as sns
import matplotlib.pyplot as plt

enc_dec = sc.read_h5ad('encoder2decoder_attention_score.h5ad')
fig = sns.heatmap(enc_dec.X[:100, :100], cmap='Reds')
plt.savefig('attention_heatmap_enc_dec.pdf')
plt.close()

enc = sc.read_h5ad('encoder_attention_score.h5ad')
fig = sns.heatmap(enc.X[:100, :100], cmap='Reds')
plt.savefig('attention_heatmap_enc.pdf')
plt.close()

dec = sc.read_h5ad('decoder_attention_score.h5ad')
fig = sns.heatmap(dec.X[:100, :100], cmap='Reds')
plt.savefig('attention_heatmap_dec.pdf')
plt.close()


## extract parameters: https://blog.csdn.net/qq_45100200/article/details/123766745



# python plot_atac_roc_pr.py --pred atac_predicted.h5ad --true rna2atac/atac_test_dm_100.h5ad
# python plot_atac_roc_pr.py --pred atac_predicted.h5ad --true rna2atac/atac_test_pbmc_100.h5ad

# python plot_atac_roc_pr.py --pred rna_atac_adata.h5ad --true truth_atac.h5ad

import argparse
import pandas as pd
import sklearn.metrics as metrics
import numpy as np
import scanpy as sc
import matplotlib.pyplot as plt

parser = argparse.ArgumentParser(description='Evaluate predicted atac peaks')
parser.add_argument('-p', '--pred', type=str, help='prediction')
parser.add_argument('-t', '--true', type=str, help='ground truth')
args = parser.parse_args()
pred_file = args.pred
true_file = args.true

pred_atac = sc.read_h5ad(pred_file)
print('read pred file done')
true_atac = sc.read_h5ad(true_file)
print('read true file done')

if type(pred_atac.X) != np.ndarray:
    pred_atac.X = pred_atac.X.todense()

if type(true_atac.X) != np.ndarray:
    true_atac.X = true_atac.X.todense()

pred = pd.DataFrame(pred_atac.X)
true = pd.DataFrame(true_atac.X)

## auroc
fpr, tpr, _ = metrics.roc_curve(true.values.flatten(), pred.values.flatten())
auroc = metrics.auc(fpr, tpr)
fig, ax = plt.subplots(dpi=300, figsize=(5, 5))
ax.plot(fpr, tpr)
ax.set(xlim=(0, 1.0), ylim=(0.0, 1.05),
       xlabel="False positive rate", ylabel="True positive rate",
       title=f"RNA->ATAC (AUROC={auroc:.3f})")
fig.savefig('rna2atac_auroc.pdf', dpi=600, bbox_inches="tight")
print('plot roc curve done')

## auprc
precision, recall, _thresholds = metrics.precision_recall_curve(true.values.flatten(), pred.values.flatten())
auprc = metrics.auc(recall, precision)
fig, ax = plt.subplots(dpi=300, figsize=(5, 5))
ax.plot(recall, precision)
ax.set(xlim=(0, 1.0), ylim=(0.0, 1.05),
       xlabel="Recall", ylabel="Precision",
       title=f"RNA->ATAC (AUPRC={auprc:.3f})")
fig.savefig('rna2atac_auprc.pdf', dpi=600, bbox_inches="tight")
print('plot pr curve done')


idx = []
for i in range(100):
     if sum(true[i])!=0:
         idx.append(i)



## plot atac peak distribution ##
import scanpy as sc
import numpy as np
import matplotlib.pyplot as plt

atac = sc.read_h5ad('atac_train_dm_1000.h5ad') # atac = sc.read_h5ad('atac_test_dm_100.h5ad')  atac = sc.read_h5ad('atac_test_pbmc_100.h5ad')
peak_cnt = np.count_nonzero(atac.X, axis=1)

plt.hist(peak_cnt, bins=30, color='skyblue', alpha=0.8)
plt.title('ATAC peak distribution')
plt.xlabel('Peak count')
plt.ylabel('Frequency')
plt.savefig('atac_train_dm_1000_peak_dist.pdf') # plt.savefig('atac_test_dm_100_peak_dist.pdf')  plt.savefig('atac_test_pbmc_100_peak_dist.pdf')
plt.close()


## combine rna & atac
## merge_h5ad_to_h5_train.py # modify a little from the raw one
import h5py
import numpy as np
from scipy.sparse import csr_matrix, hstack

rna  = h5py.File('rna_train_dm_1000.h5ad', 'r')
atac = h5py.File('atac_train_dm_1000.h5ad', 'r')
out  = h5py.File('train_dm_1000.h5', 'w')

g = out.create_group('matrix')
g.create_dataset('barcodes', data=rna['obs']['_index'][:])
rna_atac_csr_mat = hstack((csr_matrix(rna['X']), csr_matrix(atac['X']))).tocsr()
g.create_dataset('data', data=rna_atac_csr_mat.data)

g_2 = g.create_group('features')
g_2.create_dataset('_all_tag_keys', data=np.array([b'genome', b'interval']))
g_2.create_dataset('feature_type', data=np.append([b'Gene Expression']*rna['var']['gene_ids'].shape[0], [b'Peaks']*atac['var']['gene_ids'].shape[0]))
g_2.create_dataset('genome', data=np.array([b'GRCh38'] * (rna['var']['gene_ids'].shape[0]+atac['var']['gene_ids'].shape[0])))
g_2.create_dataset('id', data=np.append(rna['var']['gene_ids'][:], atac['var']['gene_ids'][:]))
g_2.create_dataset('interval', data=np.append(rna['var']['gene_ids'][:], atac['var']['gene_ids'][:]))
g_2.create_dataset('name', data=np.append(rna['var']['gene_name'][:], atac['var']['gene_ids'][:]))      

g.create_dataset('indices', data=rna_atac_csr_mat.indices)
g.create_dataset('indptr',  data=rna_atac_csr_mat.indptr)

l = list(rna_atac_csr_mat.shape)
l.reverse()
g.create_dataset('shape', data=l)

out.close()


##################### BABEL #####################
## train_model.py
## add following code for not filtering genes or peaks
## if args.nofilter:
##     atac_data_kwargs = {k: v for k, v in atac_data_kwargs.items() if not k.startswith("filt_")}

## modify gtf file for babel reference
head -n 5 Homo_sapiens.GRCh38.110.chr.gtf >> /fs/home/jiluzhang/BABEL/data/Homo_sapiens.GRCh38.110.chr.gtf
grep gene_name Homo_sapiens.GRCh38.110.chr.gtf | awk -F "\t" '{if($1!="X" && $1!="Y" && $1!="MT") print $0}' >> /fs/home/jiluzhang/BABEL/data/Homo_sapiens.GRCh38.110.chr.gtf
gzip Homo_sapiens.GRCh38.110.chr.gtf 
mv Homo_sapiens.GRCh38.110.chr.gtf.gz Homo_sapiens.GRCh38.100.gtf.gz

python /fs/home/jiluzhang/BABEL/bin/train_model.py --data ../train_dm_1000.h5 --outdir babel_train_out --device 1 --nofilter  # ~30 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_dm_100.h5 --outdir babel_test_out_dm_100 --device 1 --nofilter  # ~8 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_pbmc_100.h5 --outdir babel_test_out_pbmc_100 --device 1 --nofilter

python /fs/home/jiluzhang/BABEL/bin/train_model.py --data ../train_dm_500_hsr_500_1.h5 --outdir babel_train_out --device 1 --nofilter  # ~30 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_dm_100.h5 --outdir babel_test_out_dm_100 --device 1 --nofilter  # ~8 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_pbmc_100.h5 --outdir babel_test_out_pbmc_100 --device 1 --nofilter

python /fs/home/jiluzhang/BABEL/bin/train_model.py --data ../train_dm_1000_less_peaks.h5 --outdir babel_train_out --device 0 --nofilter --earlystop 10 # ~30 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_dm_100.h5 --outdir babel_test_out_dm_100_less_peaks --device 0 --nofilter  # ~8 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_pbmc_100.h5 --outdir babel_test_out_pbmc_100_less_peaks --device 0 --nofilter

python /fs/home/jiluzhang/BABEL/bin/train_model.py --data ../train_sci_car_1000.h5 --outdir babel_train_out --device 0 --nofilter --earlystop 10 # ~30 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_dm_100.h5 --outdir babel_test_out_dm_100_sci_car --device 0 --nofilter  # ~8 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_pbmc_100.h5 --outdir babel_test_out_pbmc_100_less_peaks --device 0 --nofilter


python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_five_tissues_train_out --data ../rna2atac/test_dm_100.h5 --outdir babel_five_tissues_test_out_dm_100 --device 1 --nofilter
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_five_tissues_train_out --data ../rna2atac/test_pbmc_100.h5 --outdir babel_five_tissues_test_out_pbmc_100 --device 2 --nofilter



##################### scMOG #####################
## Preprocessing.py.py
## add following code for not filtering genes or peaks
## if args.nofilter:
##     atac_data_kwargs = {k: v for k, v in atac_data_kwargs.items() if not k.startswith("filt_")}

## replace the gtf file

# mkdir data  # copy gtf files and snareseq fold 

## sc_data_loaders.py
## line 554: assert train_idx, "Got empty training split"    -> assert train_idx.any(), "Got empty training split"
## line 555: assert valid_idx, "Got empty validation split"  -> assert valid_idx.any(), "Got empty validation split"
## line 556: assert test_idx, "Got empty test split"         -> assert test_idx.any(), "Got empty test split"

## train.py & predict-rna.py & predict-atac.py
## add "import mpl_scatter_density" to debug "ValueError: Unknown projection 'scatter_density'"
## add "os.environ["CUDA_VISIBLE_DEVICES"] = "5""

## predict-rna.py
## "sc_rna_test_dataset = ad.read_h5ad('truth_rna_GM.h5ad')"    ->  "sc_rna_test_dataset = ad.read_h5ad('truth_rna.h5ad')"
## "sc_atac_test_dataset = ad.read_h5ad('truth_atac_GM.h5ad')"  ->  "sc_atac_test_dataset = ad.read_h5ad('truth_atac.h5ad')"
## "sc_atac_rna_test_preds =pridect(test_iter)"  ->  "sc_atac_rna_test_preds =pridect(test_iter).cpu()"

## predict-atac.py
## "sc_rna_test_dataset = ad.read_h5ad('truth_rna_GM.h5ad')"    ->  "sc_rna_test_dataset = ad.read_h5ad('truth_rna.h5ad')"
## "sc_atac_test_dataset = ad.read_h5ad('truth_atac_GM.h5ad')"  ->  "sc_atac_test_dataset = ad.read_h5ad('truth_atac.h5ad')"


time python /fs/home/jiluzhang/scMOG/scMOG_code/bin/Preprocessing.py --data train_five_tissues_1000.h5 --outdir scMOG_five_tissues --nofilter

time python /fs/home/jiluzhang/scMOG/scMOG_code/bin/train.py --outdir training_out  # ~20 min

## test dm 100
cp rna_test_dm_100.h5ad /fs/home/jiluzhang/scTranslator_new/datasets/scMOG_five_tissues/training_out/truth_rna.h5ad
cp atac_test_dm_100.h5ad /fs/home/jiluzhang/scTranslator_new/datasets/scMOG_five_tissues/training_out/truth_atac.h5ad

## covert numpy.ndarray to sparse matrix ##
import scanpy as sc
from scipy.sparse import csr_matrix

rna = sc.read_h5ad('truth_rna.h5ad')
rna.X = csr_matrix(rna.X)
rna.write('truth_rna.h5ad')

atac = sc.read_h5ad('truth_atac.h5ad')
atac.X = csr_matrix(atac.X)
atac.write('truth_atac.h5ad')
########################################

cp rna_test_pbmc_100.h5ad /fs/home/jiluzhang/scTranslator_new/datasets/scMOG_five_tissues/training_out/truth_rna.h5ad
cp atac_test_pbmc_100.h5ad /fs/home/jiluzhang/scTranslator_new/datasets/scMOG_five_tissues/training_out/truth_atac.h5ad

# convert matrix format

time python /fs/home/jiluzhang/scMOG/scMOG_code/bin/predict-atac.py --outdir predict_atac_out
time python plot_atac_roc_pr.py --pred rna_atac_adata_final.h5ad --true ../truth_atac.h5ad


################## CMOT ###################
conda create -n CMOT_new python=3.8.13
conda install pandas numpy scikit-learn
conda install -c conda-forge pot
pip install scanpy

## rename CMOT_new to CMOT
#conda remove -n CMOT --all
#conda create -n CMOT --clone CMOT_new
#conda remove -n CMOT_new --all

## modify run_cmot.py
#import scanpy as sc; from datetime import datetime  # Luz add
#print('Read sourceX done', datetime.now().replace(microsecond=0))  # Luz add
#print('Read sourceY done', datetime.now().replace(microsecond=0))  # Luz add
#print('Read targetY done', datetime.now().replace(microsecond=0))  # Luz add
#print('Step A done', datetime.now().replace(microsecond=0))  # Luz add
#print('Step B done', datetime.now().replace(microsecond=0))  # Luz add
#X = pd.read_csv(sourceX) -> X = pd.DataFrame(sc.read_h5ad(sourceX).X)
#Y = pd.read_csv(sourceY) -> Y = pd.DataFrame(sc.read_h5ad(sourceY).X)
#Y_hat = pd.read_csv(targetY) -> Y_hat = pd.DataFrame(sc.read_h5ad(targetY).X)
#X_hat_pred.to_csv(outdir+"/Norm_ModalityXhat.csv", index=False) -> pred_obs = sc.read_h5ad(targetY).obs
#                                                                   pred_var = sc.read_h5ad(sourceX).var 
#                                                                   sc.AnnData(X_hat_pred.values, obs=pred_obs, var=pred_var).write(outdir+'/predicted.h5ad')

## modify cmot_functions.py
# mask "check_mapping_quality(ot_lpl1, transp_Xs_lpl1)"  # without checking poor cells


## correspondence matrix
import numpy as np
w = np.diag([1]*1000)
np.save('W.npy', w)

python3 /fs/home/jiluzhang/CMOT/src/run_cmot.py --sourceX ../atac_train_five_tissues_1000.h5ad --sourceY ../rna_train_five_tissues_1000.h5ad \
                                                --targetY /fs/home/jiluzhang/scTranslator_new/rna2atac/rna_test_dm_100.h5ad --K 5 --d 10 \
                                                --W W.npy --hc 2 --reg_e 1e00 --reg_cl 1e00 --topFeat 100 --k 1 --outdir rna2atac_dm_100  # all parameters are default (~ 8 min)

python3 /fs/home/jiluzhang/CMOT/src/run_cmot.py --sourceX ../atac_train_five_tissues_1000.h5ad --sourceY ../rna_train_five_tissues_1000.h5ad \
                                                --targetY /fs/home/jiluzhang/scTranslator_new/rna2atac/rna_test_pbmc_100.h5ad --K 5 --d 10 \
                                                --W W.npy --hc 2 --reg_e 1e00 --reg_cl 1e00 --topFeat 100 --k 1 --outdir rna2atac_pbmc_100 

## convert csv to h5ad ##
import pandas as pd
dat = pd.read_csv('tmp.csv')

import scanpy as sc
true = sc.read_h5ad('/fs/home/jiluzhang/scTranslator_new/rna2atac/atac_test_dm_100.h5ad')
true = true[:2, :]
pred = sc.AnnData(dat, obs=true.obs, var=true.var)
pred.write('atac_predicted.h5ad')
true.write('atac_test_dm_100.h5ad')



python plot_atac_roc_pr.py --pred predicted.h5ad --true /fs/home/jiluzhang/scTranslator_new/rna2atac/atac_test_dm_100.h5ad
python plot_atac_roc_pr.py --pred predicted.h5ad --true /fs/home/jiluzhang/scTranslator_new/rna2atac/atac_test_pbmc_100.h5ad


########################## Polarbear ##########################
## python s1.py
## adultbrainfull50_atac_outer_peaks.txt
## adultbrainfull50_atac_outer_single.mtx
## adultbrainfull50_atac_outer_single_barcodes.tsv

import scanpy as sc
from scipy.io import mmwrite
import pandas as pd
from scipy.sparse import csr_matrix

atac = sc.read_h5ad('../atac_train_five_tissues_1000.h5ad')
peak = pd.DataFrame({'pos': atac.var_names})  # double check var_names!!!
peak.to_csv('adultbrainfull50_atac_outer_peaks.txt', index=False, header=False)
print('atac_train_five_tissues_1000.h5ad done')

mmwrite('adultbrainfull50_atac_outer_single.mtx', csr_matrix(atac.X.astype('int')))
print('adultbrainfull50_atac_outer_single.mtx done')

barcode = pd.DataFrame({'index': atac.obs_names})
barcode.to_csv('adultbrainfull50_atac_outer_single_barcodes.tsv', index=False)
print('adultbrainfull50_atac_outer_single_barcodes.tsv done')


## adultbrainfull50_atac_outer_single_barcodes_dataset.mtx (seems batch info)
echo "%%MatrixMarket matrix coordinate integer general" >> adultbrainfull50_atac_outer_single_barcodes_dataset.mtx
echo "%" >> adultbrainfull50_atac_outer_single_barcodes_dataset.mtx
echo "1000 11 1000" >> adultbrainfull50_atac_outer_single_barcodes_dataset.mtx
for i in `seq 1000`;do echo "$i 3 1" >> adultbrainfull50_atac_outer_single_barcodes_dataset.mtx;done


## adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx
## adultbrainfull50_atac_outer_snareseq_barcodes.tsv
## adultbrainfull50_atac_outer_snareseq.mtx
cp adultbrainfull50_atac_outer_single_barcodes_dataset.mtx adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx
cp adultbrainfull50_atac_outer_single_barcodes.tsv adultbrainfull50_atac_outer_snareseq_barcodes.tsv
cp adultbrainfull50_atac_outer_single.mtx adultbrainfull50_atac_outer_snareseq.mtx


## python s2.py
## adultbrainfull50_rna_outer_genes.txt
## adultbrainfull50_rna_outer_single.mtx
## adultbrainfull50_rna_outer_single_barcodes.tsv

import scanpy as sc
from scipy.io import mmwrite
import pandas as pd
from scipy.sparse import csr_matrix

rna = sc.read_h5ad('../rna_train_five_tissues_1000.h5ad')
gene = pd.DataFrame({'pos': rna.var_names})
gene.to_csv('adultbrainfull50_rna_outer_genes.txt', index=False, header=False)
print('adultbrainfull50_rna_outer_genes.txt done')

mmwrite('adultbrainfull50_rna_outer_single.mtx', csr_matrix(rna.X.astype('int')))
print('adultbrainfull50_rna_outer_single.mtx done')

barcode = pd.DataFrame({'index': rna.obs_names})
barcode.to_csv('adultbrainfull50_rna_outer_single_barcodes.tsv', index=False)
print('adultbrainfull50_rna_outer_single_barcodes.tsv done')


## adultbrainfull50_rna_outer_single_barcodes_dataset.mtx
cp adultbrainfull50_atac_outer_single_barcodes_dataset.mtx adultbrainfull50_rna_outer_single_barcodes_dataset.mtx


## adultbrainfull50_rna_outer_snareseq_barcodes_dataset.mtx
## adultbrainfull50_rna_outer_snareseq_barcodes.tsv
## adultbrainfull50_rna_outer_snareseq.mtx
cp adultbrainfull50_rna_outer_single_barcodes_dataset.mtx adultbrainfull50_rna_outer_snareseq_barcodes_dataset.mtx
cp adultbrainfull50_rna_outer_single_barcodes.tsv adultbrainfull50_rna_outer_snareseq_barcodes.tsv
cp adultbrainfull50_rna_outer_single.mtx adultbrainfull50_rna_outer_snareseq.mtx



## python s1.py
## adultbrainfull50_atac_outer_peaks.txt
## adultbrainfull50_atac_outer_snareseq.mtx
## adultbrainfull50_atac_outer_snareseq_barcodes.tsv

import scanpy as sc
from scipy.io import mmwrite
import pandas as pd
from scipy.sparse import csr_matrix

atac = sc.read_h5ad('../../atac_train_five_tissues_1000.h5ad')
peak = pd.DataFrame({'pos': atac.var['gene_ids']})  # double check var_names!!!
peak.to_csv('adultbrainfull50_atac_outer_peaks.txt', index=False, header=False)
print('atac_train_five_tissues_1000.h5ad done')

mmwrite('adultbrainfull50_atac_outer_snareseq.mtx', csr_matrix(atac.X.astype('int')))
print('adultbrainfull50_atac_outer_snareseq.mtx done')

barcode = pd.DataFrame({'index': atac.obs_names})
barcode.to_csv('adultbrainfull50_atac_outer_snareseq_barcodes.tsv', index=False)
print('adultbrainfull50_atac_outer_snareseq_barcodes.tsv done')




## adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx (seems batch info)
echo "%%MatrixMarket matrix coordinate integer general" >> adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx
echo "%" >> adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx
echo "1000 11 1000" >> adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx
for i in `seq 200`;do echo "$i 1 1" >> adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx;done
for i in `seq 201 400`;do echo "$i 2 1" >> adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx;done
for i in `seq 401 600`;do echo "$i 3 1" >> adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx;done
for i in `seq 601 800`;do echo "$i 4 1" >> adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx;done
for i in `seq 801 1000`;do echo "$i 5 1" >> adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx;done


## adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx
## adultbrainfull50_atac_outer_snareseq_barcodes.tsv
## adultbrainfull50_atac_outer_snareseq.mtx
cp adultbrainfull50_atac_outer_single_barcodes_dataset.mtx adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx
cp adultbrainfull50_atac_outer_single_barcodes.tsv adultbrainfull50_atac_outer_snareseq_barcodes.tsv
cp adultbrainfull50_atac_outer_single.mtx adultbrainfull50_atac_outer_snareseq.mtx


## python s2.py
## adultbrainfull50_rna_outer_genes.txt
## adultbrainfull50_rna_outer_single.mtx
## adultbrainfull50_rna_outer_single_barcodes.tsv

import scanpy as sc
from scipy.io import mmwrite
import pandas as pd
from scipy.sparse import csr_matrix

rna = sc.read_h5ad('../rna_train_five_tissues_1000.h5ad')
gene = pd.DataFrame({'pos': rna.var_names})
gene.to_csv('adultbrainfull50_rna_outer_genes.txt', index=False, header=False)
print('adultbrainfull50_rna_outer_genes.txt done')

mmwrite('adultbrainfull50_rna_outer_single.mtx', csr_matrix(rna.X.astype('int')))
print('adultbrainfull50_rna_outer_single.mtx done')

barcode = pd.DataFrame({'index': rna.obs_names})
barcode.to_csv('adultbrainfull50_rna_outer_single_barcodes.tsv', index=False)
print('adultbrainfull50_rna_outer_single_barcodes.tsv done')


## adultbrainfull50_rna_outer_single_barcodes_dataset.mtx
cp adultbrainfull50_atac_outer_single_barcodes_dataset.mtx adultbrainfull50_rna_outer_single_barcodes_dataset.mtx


## adultbrainfull50_rna_outer_snareseq_barcodes_dataset.mtx
## adultbrainfull50_rna_outer_snareseq_barcodes.tsv
## adultbrainfull50_rna_outer_snareseq.mtx
cp adultbrainfull50_rna_outer_single_barcodes_dataset.mtx adultbrainfull50_rna_outer_snareseq_barcodes_dataset.mtx
cp adultbrainfull50_rna_outer_single_barcodes.tsv adultbrainfull50_rna_outer_snareseq_barcodes.tsv
cp adultbrainfull50_rna_outer_single.mtx adultbrainfull50_rna_outer_snareseq.mtx




## training (with single data)
python /fs/home/jiluzhang/Polarbear/bin/run_polarbear.py --path_x adultbrainfull50_rna_outer_snareseq.mtx        \
                                                         --path_y adultbrainfull50_atac_outer_snareseq.mtx       \
                                                         --outdir output_semi_gpu                                \
                                                         --patience 45                                           \
                                                         --path_x_single adultbrainfull50_rna_outer_single.mtx   \
                                                         --path_y_single adultbrainfull50_atac_outer_single.mtx  \
                                                         --train_test_split random                               \
                                                         --train train --batch_size 256  # ~4.5 h

# need pre-trained model fold (***step4)
python /fs/home/jiluzhang/Polarbear/bin/run_polarbear.py --path_x adultbrainfull50_rna_outer_snareseq.mtx        \
                                                         --path_y adultbrainfull50_atac_outer_snareseq.mtx       \
                                                         --outdir output_semi_gpu                                \
                                                         --patience 45                                           \
                                                         --path_x_single adultbrainfull50_rna_outer_single.mtx   \
                                                         --path_y_single adultbrainfull50_atac_outer_single.mtx  \
                                                         --train_test_split random                               \
                                                         --train predict --predict predict --batch_size 256

## training (only paired data)
python /fs/home/jiluzhang/Polarbear/bin/run_polarbear.py --path_x adultbrainfull50_rna_outer_snareseq.mtx        \
                                                         --path_y adultbrainfull50_atac_outer_snareseq.mtx       \
                                                         --outdir output_semi_gpu                                \
                                                         --patience 45                                           \
                                                         --path_x_single nornasingle                             \
                                                         --path_y_single noatacsingle                            \
                                                         --train_test_split random                               \
                                                         --train train --batch_size 256  # ~2.5 h

python /fs/home/jiluzhang/Polarbear/bin/run_polarbear.py --path_x adultbrainfull50_rna_outer_snareseq.mtx        \
                                                         --path_y adultbrainfull50_atac_outer_snareseq.mtx       \
                                                         --outdir output_semi_gpu                                \
                                                         --patience 45                                           \
                                                         --path_x_single nornasingle                             \
                                                         --path_y_single noatacsingle                            \
                                                         --train_test_split random                               \
                                                         --train predict --predict predict --batch_size 256


python plot_atac_roc_pr.py --pred atac_predicted.h5ad --true atac_test_dm_100.h5ad


    if predict == 'predict':
        output_prefix = sim_url + '_test'
        pred_rna_norm(autoencoder, data_rna_train.shape[1], data_atac, data_batch_atac, output_prefix=output_prefix)
        pred_atac_norm(autoencoder, data_rna, data_batch_rna, data_atac_train.shape[1], output_prefix)





## cell-wise
cell_auroc = []
cell_cnt = pred.shape[0]
for i in range(cell_cnt):
    fpr, tpr, _ = metrics.roc_curve(true.iloc[i], pred.iloc[i])
    cell_auroc.append(round(metrics.auc(fpr, tpr), 4))
print('Cell-wise AUROC:', np.nanmean(cell_auroc))

## peak-wise
peak_auroc = []
peak_cnt = pred.shape[1]
for i in tqdm(range(peak_cnt)):
    true_v, pred_v = true.iloc[:, i], pred.iloc[:, i]
    if sum(true_v)!=0 and sum(true_v)!=len(true_v):
        fpr, tpr, _ = metrics.roc_curve(true_v, pred_v)
        peak_auroc.append(round(metrics.auc(fpr, tpr), 4))
print('Peak-wise AUROC:', np.nanmean(peak_auroc))

#All-wise AUROC: 0.6111091215234794
#Cell-wise AUROC: 0.6648445614035088
#Peak-wise AUROC: 0.4931407889952733



import pandas as pd
import numpy as np
pred = pd.read_table('cell_2_pred.bedgraph', header=None)
true = pd.read_table('cell_2_true.bedgraph', header=None)
dat = pd.concat([pred, true[3]], axis=1)
dat.columns = ['chr', 'start', 'end', 'pred', 'true']
for i in np.arange(0.95, 0.99, 0.01):
    print('i:', i, end='    ')
    print('precision:',  sum((dat['pred']>i) & (dat['true']==1)) / sum(dat['pred']>i), end='    ')
    print('recall:', sum((dat['pred']>i) & (dat['true']==1)) / sum(dat['true']==1))


from torchmetrics import AUROC
import torch
auroc = AUROC(task='binary')
print(auroc(torch.tensor(dat['pred'].values), torch.tensor(dat['true'].values)))



####################################### Pan-cancer multiomic data ##########################################
## https://data.humantumoratlas.org/explore?selectedFilters=%5B%7B%22group%22%3A%22AtlasName%22%2C%22value%22%3A%22HTAN+WUSTL%22%7D%5D&tab=file
pip install synapseclient

import synapseclient
syn = synapseclient.Synapse()
syn.login('Luz','57888282')
syn52176724 = syn.get(entity='syn52176724', downloadLocation='.')
