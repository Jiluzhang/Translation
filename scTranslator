# scTranslator: https://github.com/TencentAILabHealthcare/scTranslator
# performer: https://github.com/lucidrains/performer-pytorch
# transformer test: https://github.com/rogershijin/GANOLI

######################################### Installation #########################################
conda create -n scTranslator python=3.8.13
pip install scipy==1.9.1 numpy==1.21.5 pandas==1.5.1 scikit-learn==1.1.2 scanpy==1.9.1  # numba 0.58.1 requires numpy<1.27, >=1.22 (1.24.4)
pip install matplotlib==3.6.3  # import scanpy bug: TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases
pip install einops local_attention
conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch  # debug: RuntimeError: CUDA error: no kernel image is available for execution on the device
wget -c https://codeload.github.com/TencentAILabHealthcare/scTranslator/zip/refs/heads/main


######################################### run model use provided data (RNA -> Protein) #########################################
scp -P 6122 GSM2685244_protein_3_PBMCs_matrix_mapped.h5ad GSM2685244_mRNA_3_PBMCs_matrix_mapped.h5ad jiluzhang@10.11.41.108:/fs/home/jiluzhang/scTranslator/dataset/test/dataset2
scp -P 6122 stage2_single-cell_scTranslator.pt jiluzhang@10.11.41.108:/fs/home/jiluzhang/scTranslator/checkpoint
python code/stage3_inference_without_finetune.py \
--pretrain_checkpoint='checkpoint/stage2_single-cell_scTranslator.pt' \
--RNA_path='dataset/test/dataset2/GSM2685244_mRNA_3_PBMCs_matrix_mapped.h5ad' \
--Pro_path='dataset/test/dataset2/GSM2685244_protein_3_PBMCs_matrix_mapped.h5ad'

#Total number of origin RNA genes:  21005
#Total number of origin proteins:  44
#Total number of origin cells:  4330
## of NAN in X 0
## of NAN in X 0
#load data ended
#----------------------------------------
#single cell 20000 RNA To 1000 Protein on dataset/new_data-without_fine-tune
#Overall performance in repeat_1 costTime: 168.5123s
#Test Set: AVG mse 0.0408, AVG ccc 0.3924

#real	2m51.998s
#user	87m39.110s
#sys	1m50.236s

# output files
# args1.txt & performance_log.csv

## distributed training: https://zhuanlan.zhihu.com/p/76638962
python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 2 --master_addr '10.11.41.108' --master_port 6123 \
code/stage3_fine-tune.py  --epoch=1 --frac_finetune_test=0.1 --fix_set \
--pretrain_checkpoint='checkpoint/stage2_single-cell_scTranslator.pt' \
--RNA_path='dataset/test/dataset2/GSM2685244_mRNA_3_PBMCs_matrix_mapped.h5ad' \
--Pro_path='dataset/test/dataset2/GSM2685244_protein_3_PBMCs_matrix_mapped.h5ad'

# assign gpu
# add 'os.environ["CUDA_VISIBLE_DEVICES"]="0,1"' to 'stage3_fine-tune.py'

# nnodes:当前job包含多少个节点(单机多卡nnodes=1)
# node_rank: 当前节点的优先级
# nproc_per_node: 当前主机创建的进程数（一般设定为当前主机的GPU数量）
# master_addr: master节点的ip
# master_port: master节点的port


############################## Modify the raw scTranslator model ##############################
# performer_enc_dec.py  'self.pos_emb = nn.Embedding(85500,dim,padding_idx=0)'  85500 -> 300000
# mask 'model = torch.load(args.pretrain_checkpoint)' in 'stage3_fine-tune.py'
# utils.py: 'loss = F.mse_loss(y_hat[pro_mask], y[pro_mask])' -> 'loss = F.cross_entropy(y_hat[pro_mask], y[pro_mask])' (line 43)
#            'test_loss += F.mse_loss(y_hat[pro_mask], y[pro_mask]).item()' -> 'test_loss += F.cross_entropy(y_hat[pro_mask], y[pro_mask]).item()' (line 80)
#            'train_ccc += loss2(y_hat[pro_mask], y[pro_mask]).item()' -> 'auroc = AUROC(task='binary'); train_ccc += auroc(y_hat[pro_mask], y[pro_mask]).item()'  (line 46)
#            'test_ccc += loss2(y_hat[pro_mask], y[pro_mask]).item()' -> 'auroc = AUROC(task='binary'); test_ccc += auroc(y_hat[pro_mask], y[pro_mask]).item()'    (line 81)
#         add 'from torchmetrics import AUROC'  (line 7)
#         'loss' -> 'ce_loss' & 'ccc' -> 'auroc'
#         add 'print('Testing set: Average ce_loss: {:.4f}, Average auroc: {:.4f}'.format(test_loss, test_ccc), flush=True)' to line 84

# stage3_fine-tune.py: 'mse' -> 'cross entropy' & 'ccc' -> 'auroc' (line 234)
#                      'mse' -> 'cross entropy' & 'ccc' -> 'auroc' (line 235)
#                      add 'test_loss, test_ccc = test(model, device, test_loader)' to line 201

# performer_enc_dec.py
# add 'enc_kwargs['max_seq_len']=128' to line 200
# add 'self.d_r = nn.Linear(50000, 128)'  to line 206
# 'seq_in' -> 'self.d_r(seq_in)'  &  'seq_inID' -> seq_inID[:, :128]
# add 'dec_kwargs['max_seq_len']=256' to line 205
# add 'self.d_r_2 = nn.Linear(256, 1000)' to line 206
# 'self.dec(seq_out, seq_outID, **dec_kwargs)' -> 'self.d_r_2(self.dec(seq_out, seq_outID[:, :256], **dec_kwargs))'  line 212

# utils.py
# add '[:, :128]' to line 29
# add '[:, :128]' to line 67
# add '[:, :256]' to line 35
# add '[:, :256]' to line 73
# add 'from tqdm import tqdm' to line 7
# 'enumerate(train_loader)' -> 'enumerate(tqdm(train_loader, desc='Training', ncols=100))' line 25
# 'test_loader' -> 'tqdm(test_loader, desc='Testing', ncols=100)' line 63

# pip install torchmetrics
# pip install torcheval
...


############################## Process ATAC peaks and genes ##############################
# cCREs: wget -c https://downloads.wenglab.org/V3/GRCh38-cCREs.bed
awk '{if($1!="chrX" && $1!="chrY") print($1 "\t" $2 "\t" $3)}' GRCh38-cCREs.bed > human_cCREs.bed  # 1,036,913

# conda install -c bioconda bedtools
# pip install pybedtools

# human gtf file: wget -c https://ftp.ensembl.org/pub/release-110/gtf/homo_sapiens/Homo_sapiens.GRCh38.110.chr.gtf.gz
# gunzip Homo_sapiens.GRCh38.110.chr.gtf.gz
## centered by gene_id
grep gene_name Homo_sapiens.GRCh38.110.chr.gtf | awk -F "\t" '{if($1!="X" && $1!="Y" && $1!="MT" && $3=="gene") print$9}' | awk '{print $2}' | sed 's/"//g' | sed 's/;//g' > gene_id.txt
grep gene_name Homo_sapiens.GRCh38.110.chr.gtf | awk -F "\t" '{if($1!="X" && $1!="Y" && $1!="MT" && $3=="gene") print$9}' | awk '{print $6}' | sed 's/"//g' | sed 's/;//g' > gene_name.txt
paste gene_id.txt gene_name.txt > human_genes.txt  # 39884
rm gene_id.txt gene_name.txt

## cetered by gene_name
grep gene_name Homo_sapiens.GRCh38.110.chr.gtf | awk -F "\t" '{if($1!="X" && $1!="Y" && $1!="MT" && $3=="gene") print$9}' | awk '{print $2}' | sed 's/"//g' | sed 's/;//g' > gene_id.txt
grep gene_name Homo_sapiens.GRCh38.110.chr.gtf | awk -F "\t" '{if($1!="X" && $1!="Y" && $1!="MT" && $3=="gene") print$9}' | awk '{print $6}' | sed 's/"//g' | sed 's/;//g' > gene_name.txt
paste gene_id.txt gene_name.txt | sort > human_genes_raw.txt
rm gene_id.txt gene_name.txt

import pandas as pd
dat = pd.read_table('human_genes_raw.txt', names=['gene_id', 'gene_name'])
gene_cnt = dat.groupby('gene_name').agg('count').reset_index()
gene_cnt.columns = ['gene_name', 'cnt']
out = pd.merge(dat, gene_cnt)
out = out[out['cnt']==1][['gene_id', 'gene_name']]
out.to_csv('human_genes.txt', sep='\t', index=False, header=False)  # 38244

rm human_genes_raw.txt




####################################### Train model ##########################################
time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/stage3_fine-tune.py --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=50 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 39884 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_dm_1000.h5ad' --Pro_path='rna2atac/atac_train_dm_1000.h5ad'


time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/stage3_fine-tune.py --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=50 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_dm_1000.h5ad' --Pro_path='rna2atac/atac_train_dm_1000.h5ad'  # update gene number

## 5000 cells are too much for scATAC-seq data
time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/stage3_fine-tune.py --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=50 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_dm_5000.h5ad' --Pro_path='rna2atac/atac_train_dm_5000.h5ad'

time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/conti_train.py --pretrain_checkpoint='scM2M_with_weight/dm_1000/epoch_30.pt' --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=50 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_dm_1000_2000.h5ad' --Pro_path='rna2atac/atac_train_dm_1000_2000.h5ad'


time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/conti_train.py --pretrain_checkpoint='scM2M_with_weight/dm_1000/epoch_30.pt' --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=50 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_hsr_1000.h5ad' --Pro_path='rna2atac/atac_train_hsr_1000.h5ad'


######################################################
time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/stage3_fine-tune.py --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=10 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_sci_car_1000.h5ad' --Pro_path='rna2atac/atac_train_sci_car_1000.h5ad'


time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/stage3_fine-tune.py --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=10 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='datasets/rna_train_five_tissues_1000.h5ad' --Pro_path='datasets/atac_train_five_tissues_1000.h5ad'


time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/conti_train.py --pretrain_checkpoint='scM2M_with_weight/dm_1000_hsr_1000_mix_1/epoch_10.pt' --batch_size 64 --test_batch_size 64 --lr 2e-3 --translator_depth 1 --epoch=50 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_dm_500_hsr_500_2.h5ad' --Pro_path='rna2atac/atac_train_dm_500_hsr_500_2.h5ad'

######################################################


time python -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node 1 --master_addr '10.11.41.108' --master_port 6123 \
code/conti_train.py --pretrain_checkpoint='scM2M_with_weight/dm_1000/epoch_30.pt' --batch_size 64 --test_batch_size 64 --lr 2e-4 --translator_depth 1 --epoch=50 --seed 0 --frac_finetune_test 0.1 \
--enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1 \
--RNA_path='rna2atac/rna_train_dm_1000_2000.h5ad' --Pro_path='rna2atac/atac_train_dm_1000_2000.h5ad'  # reduce learning rate

## plot attention matrix heatmap
import seaborn as snc
dat = sc.read_h5ad('encoder_attention_score.h5ad')
sns.heatmap(dat.X[:10, :10]).get_figure().savefig('attention_heatmap.pdf')




## training loss
grep -o -P 'Training set: Average wbce_loss: .{6}' scTranslator_weight_50_cell_1000.log | sed 's/Training set: Average wbce_loss: //g'
## training auprc
grep "Training set" scTranslator_weight_50_cell_1000.log | grep -o -P "Average auprc: .{6}" | sed 's/Average auprc: //g'
## training auroc
grep "Training set" scTranslator_weight_50_cell_1000.log | grep -o -P "Average auroc: .{6}" | sed 's/Average auroc: //g'
## testing loss
grep -o -P 'Testing set: Average bce_loss: .{6}' scTranslator_weight_50_cell_1000.log | sed 's/Testing set: Average bce_loss: //g'
## testing auprc
grep "Testing set" scTranslator_weight_50_cell_1000.log | grep -o -P "Average auprc: .{6}" | sed 's/Average auprc: //g'
## testing auroc
grep "Testing set" scTranslator_weight_50_cell_1000.log | grep -o -P "Average auroc: .{6}" | sed 's/Average auroc: //g'
# -o: only show the matching part


####################################### Prediction ##########################################
time python code/predict.py --pretrain_checkpoint='scM2M_with_weight/epoch_30.pt' \
--RNA_path='rna2atac/rna_test_dm_100.h5ad' --test_batch_size 64 --seed 0 --enc_max_seq_len 39884 --dec_max_seq_len 1036913 

time python code/predict.py --pretrain_checkpoint='scM2M_with_weight/epoch_30.pt' \
--RNA_path='rna2atac/rna_test_pbmc_100.h5ad' --test_batch_size 64 --seed 0 --enc_max_seq_len 39884 --dec_max_seq_len 1036913 

time python code/predict.py --pretrain_checkpoint='scM2M_with_weight/epoch_10.pt' \
--RNA_path='rna2atac/rna_test_dm_100.h5ad' --test_batch_size 64 --seed 0 --enc_max_seq_len 38244 --dec_max_seq_len 1036913 

time python code/predict.py --pretrain_checkpoint='scM2M_with_weight/epoch_10.pt' \
--RNA_path='rna2atac/rna_test_pbmc_100.h5ad' --test_batch_size 64 --seed 0 --enc_max_seq_len 38244 --dec_max_seq_len 1036913 


## obtain attention matrix
python code/attention_matrix.py --pretrain_checkpoint='scM2M_with_weight/dm_1000_hsr_1000_mix_1/epoch_10.pt' \
--RNA_path='rna2atac/rna_test_dm_100.h5ad' --Pro_path='rna2atac/atac_test_dm_100.h5ad' \
--test_batch_size 1 --seed 0 --enc_max_seq_len 38244 --dec_max_seq_len 1036913 --dim 16 --translator_depth 1 --enc_depth 1 --enc_heads 1 --dec_depth 1 --dec_heads 1



# python plot_atac_roc_pr.py --pred atac_predicted.h5ad --true rna2atac/atac_test_dm_100.h5ad
# python plot_atac_roc_pr.py --pred atac_predicted.h5ad --true rna2atac/atac_test_pbmc_100.h5ad

# python plot_atac_roc_pr.py --pred rna_atac_adata.h5ad --true truth_atac.h5ad

import argparse
import pandas as pd
import sklearn.metrics as metrics
import numpy as np
import scanpy as sc
import matplotlib.pyplot as plt

parser = argparse.ArgumentParser(description='Evaluate predicted atac peaks')
parser.add_argument('-p', '--pred', type=str, help='prediction')
parser.add_argument('-t', '--true', type=str, help='ground truth')
args = parser.parse_args()
pred_file = args.pred
true_file = args.true

pred_atac = sc.read_h5ad(pred_file)
print('read pred file done')
true_atac = sc.read_h5ad(true_file)
print('read true file done')

if type(pred_atac.X) != np.ndarray:
    pred_atac.X = pred_atac.X.todense()

if type(true_atac.X) != np.ndarray:
    true_atac.X = true_atac.X.todense()

pred = pd.DataFrame(pred_atac.X)
true = pd.DataFrame(true_atac.X)

## auroc
fpr, tpr, _ = metrics.roc_curve(true.values.flatten(), pred.values.flatten())
auroc = metrics.auc(fpr, tpr)
fig, ax = plt.subplots(dpi=300, figsize=(5, 5))
ax.plot(fpr, tpr)
ax.set(xlim=(0, 1.0), ylim=(0.0, 1.05),
       xlabel="False positive rate", ylabel="True positive rate",
       title=f"RNA->ATAC (AUROC={auroc:.3f})")
fig.savefig('rna2atac_auroc.pdf', dpi=600, bbox_inches="tight")
print('plot roc curve done')

## auprc
precision, recall, _thresholds = metrics.precision_recall_curve(true.values.flatten(), pred.values.flatten())
auprc = metrics.auc(recall, precision)
fig, ax = plt.subplots(dpi=300, figsize=(5, 5))
ax.plot(recall, precision)
ax.set(xlim=(0, 1.0), ylim=(0.0, 1.05),
       xlabel="Recall", ylabel="Precision",
       title=f"RNA->ATAC (AUPRC={auprc:.3f})")
fig.savefig('rna2atac_auprc.pdf', dpi=600, bbox_inches="tight")
print('plot pr curve done')


idx = []
for i in range(100):
     if sum(true[i])!=0:
         idx.append(i)



## plot atac peak distribution ##
import scanpy as sc
import numpy as np
import matplotlib.pyplot as plt

atac = sc.read_h5ad('atac_train_dm_1000.h5ad') # atac = sc.read_h5ad('atac_test_dm_100.h5ad')  atac = sc.read_h5ad('atac_test_pbmc_100.h5ad')
peak_cnt = np.count_nonzero(atac.X, axis=1)

plt.hist(peak_cnt, bins=30, color='skyblue', alpha=0.8)
plt.title('ATAC peak distribution')
plt.xlabel('Peak count')
plt.ylabel('Frequency')
plt.savefig('atac_train_dm_1000_peak_dist.pdf') # plt.savefig('atac_test_dm_100_peak_dist.pdf')  plt.savefig('atac_test_pbmc_100_peak_dist.pdf')
plt.close()


## combine rna & atac
## merge_h5ad_to_h5_train.py # modify a little from the raw one
import h5py
import numpy as np
from scipy.sparse import csr_matrix, hstack

rna  = h5py.File('rna_train_dm_1000.h5ad', 'r')
atac = h5py.File('atac_train_dm_1000.h5ad', 'r')
out  = h5py.File('train_dm_1000.h5', 'w')

g = out.create_group('matrix')
g.create_dataset('barcodes', data=rna['obs']['_index'][:])
rna_atac_csr_mat = hstack((csr_matrix(rna['X']), csr_matrix(atac['X']))).tocsr()
g.create_dataset('data', data=rna_atac_csr_mat.data)

g_2 = g.create_group('features')
g_2.create_dataset('_all_tag_keys', data=np.array([b'genome', b'interval']))
g_2.create_dataset('feature_type', data=np.append([b'Gene Expression']*rna['var']['gene_ids'].shape[0], [b'Peaks']*atac['var']['gene_ids'].shape[0]))
g_2.create_dataset('genome', data=np.array([b'GRCh38'] * (rna['var']['gene_ids'].shape[0]+atac['var']['gene_ids'].shape[0])))
g_2.create_dataset('id', data=np.append(rna['var']['gene_ids'][:], atac['var']['gene_ids'][:]))
g_2.create_dataset('interval', data=np.append(rna['var']['gene_ids'][:], atac['var']['gene_ids'][:]))
g_2.create_dataset('name', data=np.append(rna['var']['gene_name'][:], atac['var']['gene_ids'][:]))      

g.create_dataset('indices', data=rna_atac_csr_mat.indices)
g.create_dataset('indptr',  data=rna_atac_csr_mat.indptr)

l = list(rna_atac_csr_mat.shape)
l.reverse()
g.create_dataset('shape', data=l)

out.close()


##################### BABEL #####################
## train_model.py
## add following code for not filtering genes or peaks
## if args.nofilter:
##     atac_data_kwargs = {k: v for k, v in atac_data_kwargs.items() if not k.startswith("filt_")}

## modify gtf file for babel reference
head -n 5 Homo_sapiens.GRCh38.110.chr.gtf >> /fs/home/jiluzhang/BABEL/data/Homo_sapiens.GRCh38.110.chr.gtf
grep gene_name Homo_sapiens.GRCh38.110.chr.gtf | awk -F "\t" '{if($1!="X" && $1!="Y" && $1!="MT") print $0}' >> /fs/home/jiluzhang/BABEL/data/Homo_sapiens.GRCh38.110.chr.gtf
gzip Homo_sapiens.GRCh38.110.chr.gtf 
mv Homo_sapiens.GRCh38.110.chr.gtf.gz Homo_sapiens.GRCh38.100.gtf.gz

python /fs/home/jiluzhang/BABEL/bin/train_model.py --data ../train_dm_1000.h5 --outdir babel_train_out --device 1 --nofilter  # ~30 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_dm_100.h5 --outdir babel_test_out_dm_100 --device 1 --nofilter  # ~8 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_pbmc_100.h5 --outdir babel_test_out_pbmc_100 --device 1 --nofilter

python /fs/home/jiluzhang/BABEL/bin/train_model.py --data ../train_dm_500_hsr_500_1.h5 --outdir babel_train_out --device 1 --nofilter  # ~30 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_dm_100.h5 --outdir babel_test_out_dm_100 --device 1 --nofilter  # ~8 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_pbmc_100.h5 --outdir babel_test_out_pbmc_100 --device 1 --nofilter

python /fs/home/jiluzhang/BABEL/bin/train_model.py --data ../train_dm_1000_less_peaks.h5 --outdir babel_train_out --device 0 --nofilter --earlystop 10 # ~30 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_dm_100.h5 --outdir babel_test_out_dm_100_less_peaks --device 0 --nofilter  # ~8 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_pbmc_100.h5 --outdir babel_test_out_pbmc_100_less_peaks --device 0 --nofilter

python /fs/home/jiluzhang/BABEL/bin/train_model.py --data ../train_sci_car_1000.h5 --outdir babel_train_out --device 0 --nofilter --earlystop 10 # ~30 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_dm_100.h5 --outdir babel_test_out_dm_100_sci_car --device 0 --nofilter  # ~8 min
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint babel_train_out --data ../test_pbmc_100.h5 --outdir babel_test_out_pbmc_100_less_peaks --device 0 --nofilter



## cell-wise
cell_auroc = []
cell_cnt = pred.shape[0]
for i in range(cell_cnt):
    fpr, tpr, _ = metrics.roc_curve(true.iloc[i], pred.iloc[i])
    cell_auroc.append(round(metrics.auc(fpr, tpr), 4))
print('Cell-wise AUROC:', np.nanmean(cell_auroc))

## peak-wise
peak_auroc = []
peak_cnt = pred.shape[1]
for i in tqdm(range(peak_cnt)):
    true_v, pred_v = true.iloc[:, i], pred.iloc[:, i]
    if sum(true_v)!=0 and sum(true_v)!=len(true_v):
        fpr, tpr, _ = metrics.roc_curve(true_v, pred_v)
        peak_auroc.append(round(metrics.auc(fpr, tpr), 4))
print('Peak-wise AUROC:', np.nanmean(peak_auroc))

#All-wise AUROC: 0.6111091215234794
#Cell-wise AUROC: 0.6648445614035088
#Peak-wise AUROC: 0.4931407889952733



import pandas as pd
import numpy as np
pred = pd.read_table('cell_2_pred.bedgraph', header=None)
true = pd.read_table('cell_2_true.bedgraph', header=None)
dat = pd.concat([pred, true[3]], axis=1)
dat.columns = ['chr', 'start', 'end', 'pred', 'true']
for i in np.arange(0.95, 0.99, 0.01):
    print('i:', i, end='    ')
    print('precision:',  sum((dat['pred']>i) & (dat['true']==1)) / sum(dat['pred']>i), end='    ')
    print('recall:', sum((dat['pred']>i) & (dat['true']==1)) / sum(dat['true']==1))


from torchmetrics import AUROC
import torch
auroc = AUROC(task='binary')
print(auroc(torch.tensor(dat['pred'].values), torch.tensor(dat['true'].values)))



####################################### Pan-cancer multiomic data ##########################################
## https://data.humantumoratlas.org/explore?selectedFilters=%5B%7B%22group%22%3A%22AtlasName%22%2C%22value%22%3A%22HTAN+WUSTL%22%7D%5D&tab=file
pip install synapseclient

import synapseclient
syn = synapseclient.Synapse()
syn.login('Luz','57888282')
syn52176724 = syn.get(entity='syn52176724', downloadLocation='.')
