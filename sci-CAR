## gene location ~ peak location

## https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE117089

# links.txt
for link in `cat links.txt`;do wget -c $link;done

#GSM3271040	HEK293T, NIH/3T3, A549 cells, sci-CAR RNA-seq
# https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM3271nnn/GSM3271040/suppl/GSM3271040_RNA_sciCAR_A549_cell.txt.gz
# https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM3271nnn/GSM3271040/suppl/GSM3271040_RNA_sciCAR_A549_gene.txt.gz
# https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM3271nnn/GSM3271040/suppl/GSM3271040_RNA_sciCAR_A549_gene_count.txt.gz

#GSM3271041	HEK293T, NIH/3T3, A549 cells, sci-CAR ATAC-seq
# https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM3271nnn/GSM3271041/suppl/GSM3271041_ATAC_sciCAR_A549_cell.txt.gz
# https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM3271nnn/GSM3271041/suppl/GSM3271041_ATAC_sciCAR_A549_peak.txt.gz
# https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM3271nnn/GSM3271041/suppl/GSM3271041_ATAC_sciCAR_A549_peak_count.txt.gz

pip install scanpy

################################################## CMOT ######################################################
# X: gene expression            (row: cell, column: gene)
# Y: chromatin accessibility
# gene_num: 113153
# cell_num: 6093


## process RNA (GSM3271040)
mkdir processed && cd processed
cp ../GSM3271040_RNA_sciCAR_A549_gene_count.txt.gz matrix.mtx.gz

zcat ../GSM3271040_RNA_sciCAR_A549_gene.txt.gz | sed '1d' | awk -F "," '{print $1 "\t" $3 "\t" "Gene Expression"}' > features.tsv
gzip features.tsv

zcat ../GSM3271040_RNA_sciCAR_A549_cell.txt.gz | sed '1d' | sed 's/,/_/g' > barcodes.tsv
gzip barcodes.tsv


## process ATAC (GSM3271041)
mkdir processed && cd processed

cp ../GSM3271041_ATAC_sciCAR_A549_peak_count.txt.gz matrix.mtx.gz

zcat ../GSM3271041_ATAC_sciCAR_A549_peak.txt.gz | sed '1d' | awk -F "," '{print $2}' | awk -F "-" '{print "chr" $1 ":" $2 "-" $3 "\t" "Peaks"}' \
                                                | awk '{print $1 "\t" $1 "\t" $2}' > features.tsv
gzip features.tsv

zcat ../GSM3271041_ATAC_sciCAR_A549_cell.txt.gz | sed '1d' | sed 's/,/_/g' > barcodes.tsv
gzip barcodes.tsv


## process co-assay
import scanpy as sc
import numpy as np
import pandas as pd

# RNA #
rna = sc.read_10x_mtx('GSM3271040/processed', cache=True)  # duplicated gene names: SNORD116-1  SNORD116-2  SNORD116-3...
# 6093 × 113153

rna.obs['cell_type'] = [x.split('_')[1] for x in rna.obs_names]
rna.obs['treatment'] = [x.split('_')[-1] for x in rna.obs_names]
rna.obs['raw'] = rna.obs_names
rna.obs_names = [x.split('_')[0] for x in rna.obs_names]
rna = rna[(rna.obs['cell_type'].isin(['293T', 'A549'])) & (rna.obs['treatment'].isin(['NA', '0'])), :]
# 1989 × 113153

sc.pp.filter_cells(rna, min_genes=200)
sc.pp.filter_cells(rna, max_genes=7000)
# 1989 × 113153 (no cell filtered)

rna.var['mt'] = rna.var_names.str.startswith('mt-')
rna = rna[:, rna.var['mt']==0]
# 1989 × 113116


# ATAC #
atac = sc.read_10x_mtx('GSM3271041/processed', cache=True, gex_only=False) 
# 6085 × 189603

atac.obs['species'] = [x.split('_')[1] for x in atac.obs_names]
atac.obs['treatment'] = [x.split('_')[-3] if x.split('_')[-3]!='3T3' else 'NA' for x in atac.obs_names]

cell_type = []
for i in range(len(atac.obs_names)):
    if atac.obs['species'][i]=='Human':
        cell_type.append(atac.obs_names[i].split('_')[2])
    elif atac.obs['species'][i]=='Mouse':
        cell_type.append('3T3')
    else:
        cell_type.append('Unknown')

atac.obs['cell_type'] = cell_type
atac.obs['raw'] = atac.obs_names
atac.obs_names = [x.split('_')[0] for x in atac.obs_names]
atac = atac[(atac.obs['species']=='Human') & (atac.obs['treatment'].isin(['NA', '0h'])), :]
# 2048 × 189603

atac.var['chrom'] = [x.split(':')[0] for x in atac.var_names]
atac = atac[:, atac.var['chrom'].isin(['chr'+str(i) for i in [*range(1, 23), 'X', 'Y']])]
# 2048 × 179288

rna_idx = rna.obs_names                                # 1989
atac_idx = atac.obs_names                              # 2048
co_idx = [idx for idx in rna_idx if idx in atac_idx]   # 1422

rna = rna[co_idx, :]
atac = atac[co_idx, :]

rna.write('RNA.h5ad')
atac.write('ATAC.h5ad')

rna_out = pd.DataFrame(data=rna.X.todense(), index=rna.obs_names, columns=rna.var_names)       # 1422 * 113116
rna_out.to_csv('RNA.csv', index=False)  # ~2.5 min    

atac_out = pd.DataFrame(data=atac.X.todense(), index=atac.obs_names, columns=atac.var_names)   # 1422 * 179288
atac_out[atac_out>0] = 1
atac_out.to_csv('ATAC.csv', index=False)  # ~4.5 min


## split dataset to train & test (0.8, 0.2)
import random

train_cnt = int(len(co_idx)*0.8)
co_idx_shuf = co_idx.copy()
random.seed(0)
random.shuffle(co_idx_shuf)
train_idx = co_idx_shuf[:train_cnt]
test_idx = co_idx_shuf[train_cnt:]

rna_out.loc[train_idx].to_csv('RNA_train.csv', index=False)   
rna_out.loc[test_idx].to_csv('RNA_test.csv', index=False) 

atac_out.loc[train_idx].to_csv('ATAC_train.csv', index=False) 
atac_out.loc[test_idx].to_csv('ATAC_test.csv', index=False) 


## correspondence matrix
w = np.diag([1]*train_cnt)
np.save('W.npy', w)


## modify run_cmot.py
#from datetime import datetime  # Luz add
#print('Read sourceX done', datetime.now().replace(microsecond=0))  # Luz add
#print('Read sourceY done', datetime.now().replace(microsecond=0))  # Luz add
#print('Read targetY done', datetime.now().replace(microsecond=0))  # Luz add
#print('Step A done', datetime.now().replace(microsecond=0))  # Luz add
#print('Step B done', datetime.now().replace(microsecond=0))  # Luz add

## modify cmot_functions.py
# mask "check_mapping_quality(ot_lpl1, transp_Xs_lpl1)"  # without checking poor cells


## cal_pearson_r.py
# python cal_pearson_r.py --pred results/Norm_ModalityXhat.csv --true RNA_test.csv
import argparse
import pandas as pd
from scipy import stats
import numpy as np

parser = argparse.ArgumentParser(description='Calculate Pearson correlation')
parser.add_argument('-p', '--pred', type=str, help='prediction')
parser.add_argument('-t', '--true', type=str, help='ground truth')
args = parser.parse_args()
pred_file = args.pred
true_file = args.true

pred = pd.read_csv(pred_file)
print('read pred file done')
true = pd.read_csv(true_file)
print('read true file done')

print('All-wise Pearson r:', stats.pearsonr(pred.values.flatten(), true.values.flatten())[0])

## cell-wise
cell_r = []
cell_cnt = pred.shape[0]
cell_r = [round(stats.pearsonr(pred.iloc[i], true.iloc[i])[0], 4) for i in range(cell_cnt)]
print('Cell-wise Pearson r:', np.nanmean(cell_r))

## gene-wise
gene_r = []
gene_cnt = pred.shape[1]
gene_r = [round(stats.pearsonr(pred.iloc[:, i], true.iloc[:, i])[0], 4) for i in range(gene_cnt)]
print('Gene-wise Pearson r:', np.nanmean(gene_r))


## cal_auroc.py
# python cal_auroc.py --pred rna2atac/Norm_ModalityXhat.csv --true ATAC_test.csv

import argparse
import pandas as pd
import sklearn.metrics as metrics
import numpy as np

parser = argparse.ArgumentParser(description='Calculate AUROC')
parser.add_argument('-p', '--pred', type=str, help='prediction')
parser.add_argument('-t', '--true', type=str, help='ground truth')
args = parser.parse_args()
pred_file = args.pred
true_file = args.true

pred = pd.read_csv(pred_file)
print('read pred file done')
true = pd.read_csv(true_file)
print('read true file done')

## all-wise
fpr, tpr, _ = metrics.roc_curve(true.values.flatten(), pred.values.flatten())
print('All-wise AUROC:', metrics.auc(fpr, tpr))

## cell-wise
cell_auroc = []
cell_cnt = pred.shape[0]
for i in range(cell_cnt):
    fpr, tpr, _ = metrics.roc_curve(true.iloc[i], pred.iloc[i])
    cell_auroc.append(round(metrics.auc(fpr, tpr), 4))
print('Cell-wise AUROC:', np.nanmean(cell_auroc))

## peak-wise
peak_auroc = []
peak_cnt = pred.shape[1]
for i in range(peak_cnt):
    true_v, pred_v = true.iloc[:, i], pred.iloc[:, i]
    if sum(true_v)!=0 and sum(true_v)!=len(true_v):
        fpr, tpr, _ = metrics.roc_curve(true_v, pred_v)
        peak_auroc.append(round(metrics.auc(fpr, tpr), 4))
print('Peak-wise AUROC:', np.nanmean(peak_auroc))


## ATAC to RNA
mkdir atac2rna && cd atac2rna
python3 ~/CMOT/src/run_cmot.py --sourceX ../RNA_train.csv --sourceY ../ATAC_train.csv --targetY ../ATAC_test.csv --K 5 --d 10 \
                               --W ../W.npy --hc 2 --reg_e 1e00 --reg_cl 1e00 --topFeat 100 --k 1 --outdir .
python cal_pearson_r.py --pred atac2rna/Norm_ModalityXhat.csv --true RNA_test.csv  # ~ 2.5 min   
#All-wise Pearson r: 0.3494361547578832
#Cell-wise Pearson r: 0.3978905263157895
#Gene-wise Pearson r: 0.004764645390070921

## RNA to ATAC
mkdir rna2atac && cd rna2atac
python3 ~/CMOT/src/run_cmot.py --sourceX ../ATAC_train.csv --sourceY ../RNA_train.csv --targetY ../RNA_test.csv --K 5 --d 10 \
                               --W ../W.npy --hc 2 --reg_e 1e00 --reg_cl 1e00 --topFeat 100 --k 1 --outdir .
python cal_auroc.py --pred rna2atac/Norm_ModalityXhat.csv --true ATAC_test.csv  # ~ 8 min
#All-wise AUROC: 0.5389898643042135
#Cell-wise AUROC: 0.5469782456140351
#Peak-wise AUROC: 0.5





## draft
#awk -F "," -v OFS="," '{NF=1000}1' RNA_train.csv > RNA_train_p.csv
#awk -F "," -v OFS="," '{NF=1000}1' RNA_test.csv > RNA_test_p.csv
#awk -F "," -v OFS="," '{NF=1000}1' ATAC_train.csv > ATAC_train_p.csv
#awk -F "," -v OFS="," '{NF=1000}1' ATAC_test.csv > ATAC_test_p.csv





############################## Polarbear ##############################
alias home='cd /fs/home/jiluzhang'

## adultbrainfull50_atac_outer_peaks.txt
## adultbrainfull50_atac_outer_single.mtx
## adultbrainfull50_atac_outer_single_barcodes.tsv

import scanpy as sc
from scipy.io import mmwrite
import pandas as pd

atac = sc.read_h5ad('../data/ATAC.h5ad')
peak = pd.DataFrame({'pos': atac.var_names})
peak.to_csv('adultbrainfull50_atac_outer_peaks.txt', index=False, header=False)

mmwrite('adultbrainfull50_atac_outer_single.mtx', atac.X.astype('int'))

barcode = pd.DataFrame({'index': atac.obs_names})
barcode.to_csv('adultbrainfull50_atac_outer_single_barcodes.tsv', index=False)


## adultbrainfull50_atac_outer_single_barcodes_dataset.mtx
echo "%%MatrixMarket matrix coordinate integer general" >> adultbrainfull50_atac_outer_single_barcodes_dataset.mtx
echo "%" >> adultbrainfull50_atac_outer_single_barcodes_dataset.mtx
echo "1422 11 1422" >> adultbrainfull50_atac_outer_single_barcodes_dataset.mtx
for i in `seq 1422`;do echo "$i 3 1" >> adultbrainfull50_atac_outer_single_barcodes_dataset.mtx;done


## adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx
## adultbrainfull50_atac_outer_snareseq_barcodes.tsv
## adultbrainfull50_atac_outer_snareseq.mtx
cp adultbrainfull50_atac_outer_single_barcodes_dataset.mtx adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx
cp adultbrainfull50_atac_outer_single_barcodes.tsv adultbrainfull50_atac_outer_snareseq_barcodes.tsv
cp adultbrainfull50_atac_outer_single.mtx adultbrainfull50_atac_outer_snareseq.mtx


## adultbrainfull50_rna_outer_genes.txt
## adultbrainfull50_rna_outer_single.mtx
## adultbrainfull50_rna_outer_single_barcodes.tsv
import scanpy as sc
from scipy.io import mmwrite
import pandas as pd

rna = sc.read_h5ad('../data/RNA.h5ad')
gene = pd.DataFrame({'pos': rna.var_names})
gene.to_csv('adultbrainfull50_rna_outer_genes.txt', index=False, header=False)

mmwrite('adultbrainfull50_rna_outer_single.mtx', rna.X)

barcode = pd.DataFrame({'index': rna.obs_names})
barcode.to_csv('adultbrainfull50_rna_outer_single_barcodes.tsv', index=False)


## adultbrainfull50_rna_outer_single_barcodes_dataset.mtx
cp adultbrainfull50_atac_outer_single_barcodes_dataset.mtx adultbrainfull50_rna_outer_single_barcodes_dataset.mtx


## adultbrainfull50_rna_outer_snareseq_barcodes_dataset.mtx
## adultbrainfull50_rna_outer_snareseq_barcodes.tsv
## adultbrainfull50_rna_outer_snareseq.mtx
cp adultbrainfull50_rna_outer_single_barcodes_dataset.mtx adultbrainfull50_rna_outer_snareseq_barcodes_dataset.mtx
cp adultbrainfull50_rna_outer_single_barcodes.tsv adultbrainfull50_rna_outer_snareseq_barcodes.tsv
cp adultbrainfull50_rna_outer_single.mtx adultbrainfull50_rna_outer_snareseq.mtx


## /data
## babel_train_barcodes.txt
## babel_valid_barcodes.txt
## babel_test_barcodes.txt

import scanpy as sc
import pandas as pd
import random

rna = sc.read_h5ad('../data/RNA.h5ad')
co_idx = list(rna.obs_names)
train_valid_cnt = int(len(co_idx)*0.8)   # train:valid:test=6:2:2
test_cnt = len(co_idx) - train_valid_cnt
valid_cnt = test_cnt
train_cnt = train_valid_cnt - valid_cnt
co_idx_shuf = co_idx.copy()

random.seed(0)
random.shuffle(co_idx_shuf)
train_idx = co_idx_shuf[:train_cnt]
valid_idx = co_idx_shuf[train_cnt:(train_cnt+valid_cnt)]
test_idx = co_idx_shuf[(train_cnt+valid_cnt):]

pd.DataFrame({'idx': train_idx}).to_csv('data/babel_train_barcodes.txt', index=False, header=False)
pd.DataFrame({'idx': valid_idx}).to_csv('data/babel_valid_barcodes.txt', index=False, header=False)
pd.DataFrame({'idx': test_idx}).to_csv('data/babel_test_barcodes.txt', index=False, header=False)


## /data/babel_genes.txt
cp adultbrainfull50_rna_outer_genes.txt data/babel_genes.txt


python /fs/home/jiluzhang/Polarbear/bin/run_polarbear.py --path_x adultbrainfull50_rna_outer_snareseq.mtx        \
                                                         --path_y adultbrainfull50_atac_outer_snareseq.mtx       \
                                                         --outdir output_semi_gpu                                \
                                                         --patience 45                                           \
                                                         --path_x_single adultbrainfull50_rna_outer_single.mtx   \
                                                         --path_y_single adultbrainfull50_atac_outer_single.mtx  \
                                                         --train_test_split babel                                \
                                                         --train train --batch_size 256 
# 538404



############################## BABEL ##############################
## combine rna & atac
## h5ad_to_h5.py # modify a little from the raw one
import h5py
import numpy as np
from scipy.sparse import csr_matrix, hstack

rna  = h5py.File('../data/RNA.h5ad', 'r')
atac = h5py.File('../data/ATAC.h5ad', 'r')
out  = h5py.File('RNA_ATAC.h5', 'w')

g = out.create_group('matrix')
g.create_dataset('barcodes', data=rna['obs']['_index'][:])
g.create_dataset('data', data=np.append(rna['X']['data'][:], atac['X']['data'][:]))

g_2 = g.create_group('features')
g_2.create_dataset('_all_tag_keys', data=np.array([b'genome', b'interval']))
g_2.create_dataset('feature_type', data=np.append([b'Gene Expression']*rna['var']['_index'].shape[0], [b'Peaks']*atac['var']['_index'].shape[0]))
g_2.create_dataset('genome', data=np.array([b'GRCh38'] * (rna['var']['_index'].shape[0]+atac['var']['_index'].shape[0])))
g_2.create_dataset('id', data=np.append(rna['var']['_index'][:], atac['var']['_index'][:]))
g_2.create_dataset('interval', data=np.append(rna['var']['_index'][:], atac['var']['_index'][:]))
g_2.create_dataset('name', data=np.append(rna['var']['_index'][:], atac['var']['_index'][:]))      

rna_atac_csr_mat = hstack((csr_matrix((rna['X']['data'], rna['X']['indices'],  rna['X']['indptr']), shape=[rna['obs']['_index'].shape[0], rna['var']['_index'].shape[0]]),
                           csr_matrix((atac['X']['data'], atac['X']['indices'],  atac['X']['indptr']), shape=[atac['obs']['_index'].shape[0], atac['var']['_index'].shape[0]])))
rna_atac_csr_mat = rna_atac_csr_mat.tocsr()

g.create_dataset('indices', data=rna_atac_csr_mat.indices)
g.create_dataset('indptr',  data=rna_atac_csr_mat.indptr)

l = list(rna_atac_csr_mat.shape)
l.reverse()
g.create_dataset('shape', data=l)

out.close()


## extract train_valid & test datasets
import scanpy as sc
import pandas as pd

dat = sc.read_10x_h5('RNA_ATAC.h5', gex_only=False)
train_idx = pd.read_csv('../Polarbear/data/babel_train_barcodes.txt', header=None)
valid_idx = pd.read_csv('../Polarbear/data/babel_valid_barcodes.txt', header=None)
test_idx  = pd.read_csv('../Polarbear/data/babel_test_barcodes.txt', header=None)

train_valid = dat[train_idx[0].tolist() + valid_idx[0].tolist(), :]
test = dat[test_idx[0].tolist(), ]

train_valid.write('train_valid.h5ad')
test.write('test.h5ad')


## transform h5ad to h5 format
import h5py
import numpy as np
from collections import Counter

def h5ad_to_h5(name):
    dat = h5py.File(name+'.h5ad', 'r')
    out = h5py.File(name+'.h5', 'w')
    
    g = out.create_group('matrix')
    g.create_dataset('barcodes', data=dat['obs']['_index'][:])
    g.create_dataset('data', data=dat['X']['data'][:])
    
    g_2 = g.create_group('features')
    g_2.create_dataset('_all_tag_keys', data=np.array([b'genome', b'interval']))
    g_2.create_dataset('feature_type', data=np.append([b'Gene Expression']*Counter(dat['var']['feature_types']['codes'][:])[0], 
                                                      [b'Peaks']*Counter(dat['var']['feature_types']['codes'][:])[1]))
    g_2.create_dataset('genome', data=np.array([b'GRCh38'] * (dat['var']['_index'].shape[0])))
    g_2.create_dataset('id', data=dat['var']['_index'][:])
    g_2.create_dataset('interval', data=dat['var']['_index'][:])
    g_2.create_dataset('name', data=dat['var']['_index'][:])   
    
    g.create_dataset('indices', data=dat['X']['indices'])
    g.create_dataset('indptr',  data=dat['X']['indptr'])
    g.create_dataset('shape', data=[dat['var']['_index'].shape[0], dat['obs']['_index'].shape[0]])  # feature * cell
    
    out.close()

h5ad_to_h5('train_valid')
h5ad_to_h5('test')

## BABEL will filter genes or peaks even when set "--nofilter"
python /fs/home/jiluzhang/BABEL/bin/train_model.py --data train_valid.h5 --outdir train_out --device 3
python /fs/home/jiluzhang/BABEL/bin/predict_model.py --checkpoint train_out --data test.h5 --outdir test_out







# python cal_pearson_r_babel.py --pred test_out/atac_rna_adata.h5ad --true test.h5
import argparse
import scanpy as sc
import pandas as pd
from scipy import stats
import numpy as np

parser = argparse.ArgumentParser(description='Calculate Pearson correlation')
parser.add_argument('-p', '--pred', type=str, help='prediction')
parser.add_argument('-t', '--true', type=str, help='ground truth')
args = parser.parse_args()
pred_file = args.pred
true_file = args.true

pred_rna = sc.read_h5ad(pred_file)
print('read pred file done')
true_rna = sc.read_10x_h5(true_file)
print('read true file done')

pred = pd.DataFrame((pred_rna.X.todense()))
true = pd.DataFrame((true_rna[:, pred_rna.var_names].X.todense()))

print('All-wise Pearson r:', stats.pearsonr(pred.values.flatten(), true.values.flatten())[0])

## cell-wise
cell_r = []
cell_cnt = pred.shape[0]
cell_r = [round(stats.pearsonr(pred.iloc[i], true.iloc[i])[0], 4) for i in range(cell_cnt)]
print('Cell-wise Pearson r:', np.nanmean(cell_r))

## gene-wise
gene_r = []
gene_cnt = pred.shape[1]
gene_r = [round(stats.pearsonr(pred.iloc[:, i], true.iloc[:, i])[0], 4) for i in range(gene_cnt)]
print('Gene-wise Pearson r:', np.nanmean(gene_r))

#All-wise Pearson r: 0.20268635480102398
#Cell-wise Pearson r: 0.27143333333333336
#Gene-wise Pearson r: -0.007835877125193198



# python cal_auroc_babel.py --pred test_out/rna_atac_adata.h5ad --true test.h5

import argparse
import pandas as pd
import sklearn.metrics as metrics
import numpy as np
import scanpy as sc

parser = argparse.ArgumentParser(description='Calculate AUROC')
parser.add_argument('-p', '--pred', type=str, help='prediction')
parser.add_argument('-t', '--true', type=str, help='ground truth')
args = parser.parse_args()
pred_file = args.pred
true_file = args.true

pred_atac = sc.read_h5ad(pred_file)
print('read pred file done')
true_atac = sc.read_10x_h5(true_file, gex_only=False)
print('read true file done')

pred = pd.DataFrame(pred_atac.X.todense())
true = pd.DataFrame(true_atac[:, pred_atac.var_names].X.todense())
true[true>0] = 1!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  # input atac matrix need to be converted to 0-1!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

## all-wise
fpr, tpr, _ = metrics.roc_curve(true.values.flatten(), pred.values.flatten())
print('All-wise AUROC:', metrics.auc(fpr, tpr))


## cell-wise
cell_auroc = []
cell_cnt = pred.shape[0]
for i in range(cell_cnt):
    fpr, tpr, _ = metrics.roc_curve(true.iloc[i], pred.iloc[i])
    cell_auroc.append(round(metrics.auc(fpr, tpr), 4))
print('Cell-wise AUROC:', np.nanmean(cell_auroc))

## peak-wise
peak_auroc = []
peak_cnt = pred.shape[1]
for i in range(peak_cnt):
    true_v, pred_v = true.iloc[:, i], pred.iloc[:, i]
    if sum(true_v)!=0 and sum(true_v)!=len(true_v):
        fpr, tpr, _ = metrics.roc_curve(true_v, pred_v)
        peak_auroc.append(round(metrics.auc(fpr, tpr), 4))
print('Peak-wise AUROC:', np.nanmean(peak_auroc))

#All-wise AUROC: 0.6111091215234794
#Cell-wise AUROC: 0.6648445614035088
#Peak-wise AUROC: 0.4931407889952733
