# CMOT: Cross-Modality Optimal Transport for multimodal inference
# Ten simple rules for defining a computational biology project
# downsample genes and peaks for Polarbear!!!


#password: wanglab_jlz_57888282
#scMOG: https://github.com/GaoLabXDU/scMOG
#BABEL: https://github.com/wukevin/babel
#Polarbear: https://github.com/Noble-Lab/Polarbear

#Gitzip for github (download the individual files)

## install miniconda
wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
chmod +x Miniconda3-latest-Linux-x86_64.sh
./Miniconda3-latest-Linux-x86_64.sh
## enter...   yes...

conda create -n scMOG python=3.7.10  # change to 3.10.12 later
conda activate scMOG

git clone https://github.com/GaoLabXDU/scMOG.git
conda install pytorch
pip install scanpy 
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple intervaltree cached_property mpl_scatter_density adjustText astropy igraph louvain leidenalg tensorboard skorch

#datasets (from BABEL)
#https://office365stanford-my.sharepoint.com/personal/wukevin_stanford_edu/_layouts/15/
#download.aspx?SourceduUrl=%2Fpersonal%2Fwukevin%5Fstanford%5Fedu%2FDocuments%2Fmanuscripts%2Fsingle%5Fcell%5Fatac%5Frna%2Fpublic%5Fdata%2Fdata%2Etar%2Egz

python ../scMOG_code/bin/Preprocessing.py --data DM_rep4.h5  --outdir test_out

## WGAN: https://zhuanlan.zhihu.com/p/25071913



#wget -c https://ftp.ncbi.nlm.nih.gov/geo/series/GSE200nnn/GSE200046/suppl/GSE200046_bm_multiome_rna.h5ad.gz
#wget -c https://ftp.ncbi.nlm.nih.gov/geo/series/GSE200nnn/GSE200046/suppl/GSE200046_bm_multiome_atac.h5ad.gz

##################### h5ad to h5 (for both scRNA-seq and scATAC-seq)#############################
## h5ad_to_h5.py
import h5py
import numpy as np
from scipy.sparse import csr_matrix, hstack

#ref = h5py.File('DM_rep4.h5', 'r')
rna  = h5py.File('GSE200046_bm_multiome_rna.h5ad', 'r')
atac = h5py.File('GSE200046_bm_multiome_atac.h5ad', 'r')
out  = h5py.File('GSE200046_bm_rna_atac.h5', 'w')

g = out.create_group('matrix')
g.create_dataset('barcodes', data=rna['obs']['index'][:])
g.create_dataset('data', data=np.append(rna['X']['data'][:], atac['X']['data'][:]))

g_2 = g.create_group('features')
g_2.create_dataset('_all_tag_keys', data=np.array([b'genome', b'interval']))
g_2.create_dataset('feature_type', data=np.append([b'Gene Expression']*rna['var']['_index'].shape[0], [b'Peaks']*atac['var']['idx'].shape[0]))
g_2.create_dataset('genome', data=np.array([b'GRCh38'] * (rna['var']['_index'].shape[0]+atac['var']['idx'].shape[0])))
g_2.create_dataset('id', data=np.append(rna['var']['_index'][:], atac['var']['_index'][:]))        # gene names for ENSMBLE ID????
g_2.create_dataset('interval', data=np.append(rna['var']['_index'][:], atac['var']['_index'][:]))  # genes for scRNA-seq????
g_2.create_dataset('name', data=np.append(rna['var']['_index'][:], atac['var']['_index'][:]))      

## https://blog.csdn.net/m0_64204369/article/details/123035598
## https://blog.csdn.net/HHTNAN/article/details/79790370
## matrix: cell*feature  shape: [feature, cell]  # confused!!!
rna_atac_csr_mat = hstack((csr_matrix((rna['X']['data'], rna['X']['indices'],  rna['X']['indptr']), shape=[rna['obs']['index'].shape[0], rna['var']['_index'].shape[0]]),
                           csr_matrix((atac['X']['data'], atac['X']['indices'],  atac['X']['indptr']), shape=[atac['obs']['index'].shape[0], atac['var']['_index'].shape[0]])))

g.create_dataset('indices', data=rna_atac_csr_mat.indices)
g.create_dataset('indptr',  data=rna_atac_csr_mat.indptr)

l = list(rna_atac_csr_mat.shape)
l.reverse()
g.create_dataset('shape', data=l)

out.close()

#test = sc.read_10x_h5('GSE200046_bm_rna_atac.h5', gex_only=False)
##################################################


# mkdir data  # copy gtf files and snareseq fold 

## sc_data_loaders.py
## line 554: assert train_idx, "Got empty training split"    -> assert train_idx.any(), "Got empty training split"
## line 555: assert valid_idx, "Got empty validation split"  -> assert valid_idx.any(), "Got empty validation split"
## line 556: assert test_idx, "Got empty test split"         -> assert test_idx.any(), "Got empty test split"

## train.py & predict-rna.py & predict-atac.py
## add "import mpl_scatter_density" to debug "ValueError: Unknown projection 'scatter_density'"
## add "os.environ["CUDA_VISIBLE_DEVICES"] = "5""

## predict-rna.py
## "sc_rna_test_dataset = ad.read_h5ad('truth_rna_GM.h5ad')"    ->  "sc_rna_test_dataset = ad.read_h5ad('truth_rna.h5ad')"
## "sc_atac_test_dataset = ad.read_h5ad('truth_atac_GM.h5ad')"  ->  "sc_atac_test_dataset = ad.read_h5ad('truth_atac.h5ad')"
## "sc_atac_rna_test_preds =pridect(test_iter)"  ->  "sc_atac_rna_test_preds =pridect(test_iter).cpu()"

## predict-atac.py
## "sc_rna_test_dataset = ad.read_h5ad('truth_rna_GM.h5ad')"    ->  "sc_rna_test_dataset = ad.read_h5ad('truth_rna.h5ad')"
## "sc_atac_test_dataset = ad.read_h5ad('truth_atac_GM.h5ad')"  ->  "sc_atac_test_dataset = ad.read_h5ad('truth_atac.h5ad')"


python h5ad_to_h5.py
python ~/scMOG/scMOG_code/bin/Preprocessing.py --data GSE20046_bm_rna_atac.h5 --outdir GSE20046_bm_preprocessed_datasets
python ~/scMOG/scMOG_code/bin/train.py  --outdir training_out
python ~/scMOG/scMOG_code/bin/predict-rna.py --outdir predict_rna_out
python ~/scMOG/scMOG_code/bin/predict-atac.py --outdir predict_atac_out

nohup time python ~/scMOG/scMOG_code/bin/train.py --outdir training_out > training_20230904.log &





########################################################### BABEL ###########################################################
conda remove -n scMoFormer --all

conda create -n BABEL python==3.7.9
pip install numpy==1.17.5 pandas==0.25.3 scipy==1.3.2 scanpy==1.4.4 skorch==0.7.0 intervaltree==3.0.2 adjusttext==0.7.3 astropy==4.0.1 tensorboard==2.0.0 
            gdown==4.0.2 captum==0.2.0 python-igraph==0.8.0 louvain==0.6.2 leidenalg==0.8.0 scikit-learn==0.21.3 umap-learn==0.3.10 
            cached_property mpl_scatter_density protobuf==3.20.0 anndata==0.6.22

## debug "AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'"
## /fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/scanpy/tools/_louvain.py
line 130: "louvain.set_rng_seed(random_state)"  ->  "#louvain.set_rng_seed(random_state)"  ## mask and pass it

time python ~/BABEL/bin/train_model.py --data DM_rep4.h5 --outdir BABEL_model --device 4                 # run sucessfully!!!
time python ~/BABEL/bin/train_model.py --data GSE20046_bm_rna_atac.h5  --outdir BABEL_model_GSE20046_bm --device 5   # cannot run successfully !!!  

## bug: "Exception: File is missing one or more required datasets."
## ~/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/scanpy/readwrite.py
## add following code:
#import h5py
#def _collect_datasets(dsets: dict, group: h5py.Group):
#    for k, v in group.items():
#        if isinstance(v, h5py.Dataset):
#            dsets[k] = v[()]
#        else:
#            _collect_datasets(dsets, v)
## "with tables.open_file(str(filename), 'r') as f:" -> "with h5py.File(str(filename), 'r') as f:"
## pass following code:
#for node in f.walk_nodes('/matrix', 'Array'):
#    dsets[node.name] = node.read()
## add following code:
# _collect_datasets(dsets, f["matrix"])
###############################################################################################################################################



############################ BABEL installation try 1 (failed) ##########################
conda create -n BABEL_new python==3.10.12

pip install -i https://pypi.tuna.tsinghua.edu.cn/simple numpy pandas scipy scanpy skorch torch intervaltree cached_property mpl_scatter_density adjustText astropy tensorboard gdown captum igraph louvain leidenalg
                                                        anndata==0.7.7

anndata
time python ~/BABEL/bin/train_model.py --data DM_rep4.h5 --outdir BABEL_model_0.7.4     ImportError: cannot import name 'is_categorical' from 'pandas.api.types'
time python ~/BABEL/bin/train_model.py --data DM_rep4.h5 --outdir BABEL_model_0.7.5     TypeError: Categorical.remove_unused_categories() got an unexpected keyword argument 'inplace'
time python ~/BABEL/bin/train_model.py --data DM_rep4.h5 --outdir BABEL_model_0.7.7     TypeError: Categorical.reorder_categories() got an unexpected keyword argument 'inplace'
time python ~/BABEL/bin/train_model.py --data DM_rep4.h5 --outdir BABEL_model_0.7.8     TypeError: Categorical.reorder_categories() got an unexpected keyword argument 'inplace'
time python ~/BABEL/bin/train_model.py --data DM_rep4.h5 --outdir BABEL_model_0.8.0rc1  KeyError: 'Could not find key 1494 in .obs_names or .var.columns.'
time python ~/BABEL/bin/train_model.py --data DM_rep4.h5 --outdir BABEL_model_0.8.0     KeyError: 'Could not find key 1494 in .obs_names or .var.columns.'

anndata==0.7.7  pandas version
time python ~/BABEL/bin/train_model.py --data DM_rep4.h5 --outdir BABEL_model_1.2.5      KeyError: 'Could not find key 1494 in .obs_names or .var.columns.'
time python ~/BABEL/bin/train_model.py --data DM_rep4.h5 --outdir BABEL_model_1.2.0      KeyError: 'Could not find key 1494 in .obs_names or .var.columns.'

anndata==0.7.4  pandas==1.2.5
time python ~/BABEL/bin/train_model.py --data DM_rep4.h5 --outdir BABEL_model_anndata_0.7.4_pandas_1.2.5   KeyError: 'Could not find key 1494 in .obs_names or .var.columns.'

time python ~/BABEL/bin/train_model.py --data DM_rep4.h5 --outdir BABEL_model_anndata_0.9.2_pandas_2.0.3_scanpy_1.9.4
time python ~/BABEL/bin/train_model.py --data DM_rep4.h5 --outdir BABEL_model_anndata_0.9.0_pandas_2.0.3_scanpy_1.9.4
####################################################################################


############################ BABEL installation try 2 (failed) ##########################
## refer to "environment_minimal.yml" & "environment.yml"
conda create -n BABEL python=3.7.10
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple anndata==0.6.22 astropy==4.0 cached_property torch==1.3 captum==0.2 
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple intervaltree gdown==4.0 leidenalg==0.8.0 louvain==0.6.2 numba==0.51.2   
# leidenalg 0.7.0  louvain 0.6.1 cannot be installed
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple numpy==1.17 pandas==0.25 seaborn scanpy==1.4.4 scikit-learn==0.21.3
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple skorch==0.7 sortedcontainers statsmodels==0.10 tensorboard==1.15 tqdm
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple umap-learn==0.3.10 mpl-scatter-density adjustText

pip install protobuf==3.20.0

## /fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/scanpy/tools/_louvain.py
line 130: "louvain.set_rng_seed(random_state)"  ->  "#louvain.set_rng_seed(random_state)"  ## mask and pass it
# pip install louvain==0.7.0
# pip install python-igraph==0.8.0  # it is for louvain and leiden clustering
# pip install torch==1.13.1         # not 1.3.0 to fit cuda version

# pip install scanpy==1.9.0          # to debug sc.read_10x_h5()
# pip install scikit-learn==0.22.0   # TypeError: __init__() got an unexpected keyword argument 'n_jobs'
# pip install dask                   # to debug "TypeError: isinstance() arg 2 must be a type or tuple of types"
# pip install anndata==0.7.4         # to debug "KeyError: 'Could not find key 1386 in .obs_names or .var.columns.'"


nohup time python ~/BABEL/bin/train_model.py --data GSE20046_bm_rna_atac.h5 --outdir BABEL_model > BABEL_training.log &

time python ~/BABEL/bin/train_model.py --data DM_rep4.h5 --outdir BABEL_model
time python ~/BABEL/bin/train_model.py --data GSE20046_bm_rna_atac.h5 --outdir BABEL_model
####################################################################################



#################### time python ~/BABEL/bin/train_model.py --data GSE20046_bm_rna_atac.h5  --outdir BABEL_model_GSE20046_bm --device 5 
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/anndata/core/anndata.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.
  from pandas.core.index import RangeIndex
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  method='lar', copy_X=True, eps=np.finfo(np.float).eps,
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  method='lar', copy_X=True, eps=np.finfo(np.float).eps,
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps, positive=False):
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  eps=np.finfo(np.float).eps, copy_X=True, positive=False):
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  EPS = np.finfo(np.float).eps
INFO:root:PyTorch CUDA version: 11.7
INFO:root:Parameter data: ['GSE20046_bm_rna_atac.h5']
INFO:root:Parameter snareseq: False
INFO:root:Parameter shareseq: None
INFO:root:Parameter nofilter: False
INFO:root:Parameter linear: False
INFO:root:Parameter clustermethod: leiden
INFO:root:Parameter validcluster: 0
INFO:root:Parameter testcluster: 1
INFO:root:Parameter outdir: /fs/home/jiluzhang/GSES20046_bm/BABEL_model_GSE20046_bm
INFO:root:Parameter naive: False
INFO:root:Parameter hidden: [16]
INFO:root:Parameter pretrain: 
INFO:root:Parameter lossweight: [1.33]
INFO:root:Parameter optim: adam
INFO:root:Parameter lr: [0.01]
INFO:root:Parameter batchsize: [512]
INFO:root:Parameter earlystop: 25
INFO:root:Parameter seed: [182822]
INFO:root:Parameter device: 5
INFO:root:Parameter ext: pdf
INFO:root:Reading RNA data
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/anndata/core/anndata.py:1237: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead
  if is_categorical(df_full[k]):
INFO:root:Read in GSE20046_bm_rna_atac.h5 for (7439, 17226) (obs x var)
Trying to set attribute `.obs` of view, making a copy.
WARNING:root:Got multiple chromosomes for gene DUS4L-BCAP29: {'7', '4'}, skipping
INFO:root:17027 genes with known positions
Trying to set attribute `.var` of view, making a copy.
Trying to set attribute `.obs` of view, making a copy.
INFO:root:Filtering 7439 cells
INFO:root:Remaining cells after min genes: 7439
INFO:root:Remaining cells after max genes: 7439
INFO:root:Computing size factors
INFO:root:Found median counts of 5459.0
INFO:root:Found maximum counts of 22721.056640625
INFO:root:Log transforming data
INFO:root:Normalizing data to zero mean unit variance
INFO:root:Clipping to 0.5 percentile
INFO:root:Constructing leiden log clustered data split with valid test cluster {'0'} {'1'}
INFO:root:Setting size normalized counts
WARNING: Consider installing the package MulticoreTSNE (https://github.com/DmitryUlyanov/Multicore-TSNE). Even for n_jobs=1 this speeds up the computation considerably and might yield better converged results.
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/neighbors/base.py:441: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  old_joblib = LooseVersion(joblib_version) < LooseVersion('0.12')
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/neighbors/base.py:441: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  old_joblib = LooseVersion(joblib_version) < LooseVersion('0.12')
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/manifold/t_sne.py:344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  error = np.finfo(np.float).max
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/manifold/t_sne.py:345: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  best_error = np.finfo(np.float).max
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/manifold/t_sne.py:344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  error = np.finfo(np.float).max
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/manifold/t_sne.py:345: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  best_error = np.finfo(np.float).max
INFO:root:Setting log-normalized size-normalized counts
WARNING: Consider installing the package MulticoreTSNE (https://github.com/DmitryUlyanov/Multicore-TSNE). Even for n_jobs=1 this speeds up the computation considerably and might yield better converged results.
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/neighbors/base.py:441: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  old_joblib = LooseVersion(joblib_version) < LooseVersion('0.12')
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/neighbors/base.py:441: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  old_joblib = LooseVersion(joblib_version) < LooseVersion('0.12')
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/manifold/t_sne.py:344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  error = np.finfo(np.float).max
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/manifold/t_sne.py:345: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  best_error = np.finfo(np.float).max
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/manifold/t_sne.py:344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  error = np.finfo(np.float).max
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/sklearn/manifold/t_sne.py:345: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  best_error = np.finfo(np.float).max
INFO:root:Created train data split with 5564 examples
INFO:root:Created valid data split with 1116 examples
INFO:root:Created test data split with 759 examples
INFO:root:Aggregating ATAC clusters
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/anndata/core/anndata.py:1237: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead
  if is_categorical(df_full[k]):
INFO:root:Read in GSE20046_bm_rna_atac.h5 for (7439, 219242) (obs x var)
Trying to set attribute `.X` of view, making a copy.
INFO:root:Filtering 213950 vars
INFO:root:Remaining vars after min count: 213754
INFO:root:Remaining vars after min cells: 213754
INFO:root:Remaining vars after max cells: 189332
INFO:root:Got predefined split, ignoring mode
INFO:root:Created train data split with 5564 examples
INFO:root:Created valid data split with 1116 examples
INFO:root:Created test data split with 759 examples
INFO:root:Checking obs names for two input datasets
INFO:root:Checking obs names for two input datasets
INFO:root:Checking obs names for two input datasets
INFO:root:Checking obs names for two input datasets
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/anndata/core/anndata.py:108: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead
  elif is_categorical(df[k]):
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/anndata/core/anndata.py:1326: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead
  and not is_categorical(df[key])
Trying to set attribute `.obs` of view, making a copy.
... storing 'source_file' as categorical
Trying to set attribute `.var` of view, making a copy.
... storing 'chrom' as categorical
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/pandas/core/arrays/categorical.py:2631: FutureWarning: The `inplace` parameter in pandas.Categorical.remove_unused_categories is deprecated and will be removed in a future version.
  res = method(*args, **kwargs)
INFO:root:ChromDecoder with 1 output activations
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:1006: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
  epoch    train_loss    valid_loss    cp     dur
-------  ------------  ------------  ----  ------
      1        2.4694        1.5918     +  8.5210
      2        1.3230        1.2394     +  8.1342
      3        1.1886        1.1810     +  7.9616
      4        1.1680        1.1568     +  8.1450
      5        1.1541        1.1483     +  8.0682
      6        1.1460        1.1426     +  8.2146
      7        1.1413        1.1399     +  8.2176
      8        1.1386        1.1388     +  8.0362
      9        1.1356        1.1378     +  8.0020
     10        1.1332        1.1374     +  8.0299
     11        1.1311        1.1373     +  8.0803
     12        1.1295        1.1366     +  8.2610
     13        1.1279        1.1367        8.1249
     14        1.1266        1.1369        8.2044
     15        1.1258        1.1366        8.0615
     16        1.1247        1.1366        8.0677
     17        1.1235        1.1366     +  8.1225
     18        1.1223        1.1356     +  8.1339
     19        1.1210        1.1358        8.1993
     20        1.1203        1.1357        8.0238
     21        1.1194        1.1355     +  8.1325
     22        1.1187        1.1351     +  8.3199
     23        1.1179        1.1344     +  8.1097
     24        1.1168        1.1345        8.2095
     25        1.1165        1.1344     +  7.9961
     26        1.1156        1.1350        8.1192
     27        1.1151        1.1340     +  8.1298
     28        1.1143        1.1343        8.1052
     29        1.1137        1.1341        8.1559
     30        1.1133        1.1337     +  8.2527
     31        1.1128        1.1336     +  8.1883
     32        1.1122        1.1344        8.1030
     33        1.1119        1.1336     +  8.3059
     34        1.1112        1.1346        8.0738
     35        1.1105        1.1337        8.1089
     36        1.1106        1.1341        8.1278
     37        1.1100        1.1333     +  8.1312
     38        1.1094        1.1333        8.5645
     39        1.1087        1.1332     +  8.0476
     40        1.1087        1.1343        8.0683
     41        1.1081        1.1335        7.9495
     42        1.1076        1.1334        7.9388
     43        1.1071        1.1337        8.0314
     44        1.1066        1.1334        7.9379
     45        1.1062        1.1333        7.9198
     46        1.1055        1.1337        8.0091
     47        1.1051        1.1336        7.9697
     48        1.1051        1.1335        8.1097
     49        1.1047        1.1338        8.0409
     50        1.1044        1.1341        7.9701
     51        1.1044        1.1343        7.9819
     52        1.1037        1.1338        7.9340
     53        1.1033        1.1342        8.0214
     54        1.1032        1.1345        8.0948
     55        1.1028        1.1339        7.9370
     56        1.1023        1.1339        8.0216
     57        1.1023        1.1340        8.0255
     58        1.1023        1.1343        7.8482
     59        1.1018        1.1347        8.1957
     60        1.1013        1.1346        8.0128
     61        1.1006        1.1349        8.0177
     62        1.1006        1.1342        8.0671
     63        1.1002        1.1348        7.8888
Stopping since valid_loss has not improved in the last 25 epochs.
INFO:root:Evaluating on test set
INFO:root:Evaluating RNA > RNA
... storing 'source_file' as categorical
... storing 'feature_types' as categorical
... storing 'genome' as categorical
... storing 'chrom' as categorical
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/anndata/core/anndata.py:101: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead
  if is_string_dtype(df[k]) and not is_categorical(df[k]):
INFO:root:Found pearson's correlation/p of 0.5653/0
INFO:root:Found spearman's collelation/p of 0.4558/0
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/mpl_scatter_density/generic_density_artist.py:77: RuntimeWarning: All-NaN slice encountered
  vmin = self._density_vmin(array)
/fs/home/jiluzhang/softwares/miniconda3/envs/BABEL/lib/python3.7/site-packages/mpl_scatter_density/generic_density_artist.py:82: RuntimeWarning: All-NaN slice encountered
  vmax = self._density_vmax(array)
INFO:root:Evaluating ATAC > ATAC
INFO:root:Found AUROC of 0.8462
INFO:root:Evaluating ATAC > RNA
... storing 'source_file' as categorical
... storing 'feature_types' as categorical
... storing 'genome' as categorical
... storing 'chrom' as categorical
INFO:root:Found pearson's correlation/p of 0.5581/0
INFO:root:Found spearman's collelation/p of 0.4533/0
INFO:root:Evaluating RNA > ATAC
INFO:root:Found AUROC of 0.8086

real	15m22.621s
user	41m58.659s
sys	16m8.144s



######################## Polarbear ########################
# alternative solution: https://github.com/qqwweee/keras-yolo3/issues/332
#                       https://forsworns.github.io/zh/blogs/20190824/


conda create -n Polarbear python=3.6.8
conda install -c anaconda tensorflow-gpu




conda create -n Polarbear -c conda-forge python==3.7.12
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple scikit-learn==0.23.2 pandas==1.3.4 tensorflow-gpu==1.13.1
conda install cudatoolkit=10.0
conda install cudnn=7.3.1
pip install protobuf==3.20.0

#cudnn_raw
cp cuda/lib64/libcudnn* /fs/home/jiluzhang/softwares/miniconda3/envs/Polarbear_new/lib
cp cuda/lib64/libcudnn* /fs/home/jiluzhang/softwares/miniconda3/pkgs/cudnn-7.3.1-cuda10.0_0/lib
cp cuda/include/cudnn.h /fs/home/jiluzhang/softwares/miniconda3/pkgs/cudnn-7.3.1-cuda10.0_0/include

conda create -n Polarbear -c conda-forge python==3.7.12
pip install scikit-learn==0.23.2 pandas==1.3.4 tensorflow-gpu==1.13.1

# bug: "ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory"
# pip install -i https://pypi.tuna.tsinghua.edu.cn/simple tensorflow-gpu==1.15.5

# bug: "Could not load dynamic library 'libcusparse.so.10.0'"
# conda install cudatoolkit=10.0

# bug: "Could not load dynamic library 'libcudnn.so.7'"
# conda install cudnn=7.6.5   
7.3.1(failed)
7.6.0(failed)
7.6.4(failed)
7.6.5(failed)

cudnn 7.4!!!!!!!!!!!!!!!

pip install scanpy==1.7.0 h5py==2.10.0 numpy==1.17.0
sc.read_mtx() seems not quicker than mmread()

run_polarbear.py
add "print()"

add ";\"
copy and paste the first line, and paste the rest code. 



###################################################################
conda create -n Polarbear -c conda-forge python==3.7.5
conda install tensorflow-gpu=1.14.0
conda install pandas scikit-learn
# python=3.7.5
# scikit-learn=1.0.2
# pandas=1.3.5
# tensorflow-gpu=1.14.0
###################################################################

## downsample to 10k peaks

# adultbrainfull50_atac_outer_peaks.txt  225333
head -n 10000 dat_raw/adultbrainfull50_atac_outer_peaks.txt > adultbrainfull50_atac_outer_peaks.txt

# adultbrainfull50_atac_outer_peaks_noXY_diffexp.txt  78286
head -n 1 dat_raw/adultbrainfull50_atac_outer_peaks_noXY_diffexp.txt > adultbrainfull50_atac_outer_peaks_noXY_diffexp.txt
sed '1d' dat_raw/adultbrainfull50_atac_outer_peaks_noXY_diffexp.txt | awk '{if($8<=10000) print$0}' >> adultbrainfull50_atac_outer_peaks_noXY_diffexp.txt

# adultbrainfull50_atac_outer_single.mtx
# %%MatrixMarket matrix coordinate integer general
# %
# 170442 225333 265340610
head -n 3 dat_raw/adultbrainfull50_atac_outer_single.mtx > adultbrainfull50_atac_outer_single.mtx
sed '1,3d' dat_raw/adultbrainfull50_atac_outer_single.mtx | awk '{if($2<=10000) print$0}' >> adultbrainfull50_atac_outer_single.mtx  # ~45s
# 225333     -> 10000
# 265340610  -> 13203920

# adultbrainfull50_atac_outer_single_barcodes.tsv  170443
#index	tissue	dev_stage	dataset	dataset_id	batch	celltype	region	n_genes
#AACGAGAGCTAAAGGAACAGAC-0-0-0-0-0-0	brain	adult	snATAC	snATAC_brain_adult	0		CEMBA190305_11F	3607
cp dat_raw/adultbrainfull50_atac_outer_single_barcodes.tsv .

# adultbrainfull50_atac_outer_single_barcodes_dataset.mtx
# %%MatrixMarket matrix coordinate integer general
# %
# 170442 11 170442
# 85607 4 1
cp dat_raw/adultbrainfull50_atac_outer_single_barcodes_dataset.mtx .

# adultbrainfull50_atac_outer_snareseq.mtx
# %%MatrixMarket matrix coordinate integer general
# %
# 10309 225333 20877991
head -n 3 dat_raw/adultbrainfull50_atac_outer_snareseq.mtx > adultbrainfull50_atac_outer_snareseq.mtx
sed '1,3d' dat_raw/adultbrainfull50_atac_outer_snareseq.mtx | awk '{if($2<=10000) print$0}' >> adultbrainfull50_atac_outer_snareseq.mtx
# 225333     -> 10000
# 20877991   -> 901671

# adultbrainfull50_atac_outer_snareseq_barcodes.tsv  10310
# index	tissue	dev_stage	dataset	dataset_id	batch	celltype	region	n_genes
# 09K_ACCCTCCGAAGC	brain	adult	SNARE-seq	SNARE-seq_brain_adult	0			3398
# cp dat_raw/adultbrainfull50_atac_outer_snareseq_barcodes.tsv .

# adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx
# %%MatrixMarket matrix coordinate integer general
# %
# 10309 11 10309
# 1 3 1
cp dat_raw/adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx .

# adultbrainfull50_rna_outer_genes.txt  17271
# Fbxl18
# Tmem158
# Csf3r
head -n 10000 dat_raw/adultbrainfull50_rna_outer_genes.txt > adultbrainfull50_rna_outer_genes

# adultbrainfull50_rna_outer_single.mtx
# %%MatrixMarket matrix coordinate integer general
# %
# 160796 17271 227527723
head -n 3 dat_raw/adultbrainfull50_rna_outer_single.mtx > adultbrainfull50_rna_outer_single.mtx
sed '1,3d' dat_raw/adultbrainfull50_rna_outer_single.mtx | awk '{if($2<=10000) print$0}' >> adultbrainfull50_rna_outer_single.mtx  # ~45s
# 17271      -> 10000
# 227527723  -> 132641415

# adultbrainfull50_rna_outer_single_barcodes.tsv  160797
# index	tissue	dev_stage	celltype	dataset	dataset_id	batch	Age	n_genes
# 10X82_2_TCTCTCACCAGTTA-brainp21, p23Neurons	brain	adult	Neurons	zeisel	zeisel_brain_adult	1	p21, p23	4446
cp dat_raw/adultbrainfull50_rna_outer_single_barcodes.tsv .

# adultbrainfull50_rna_outer_single_barcodes_dataset.mtx
# %%MatrixMarket matrix coordinate integer general
# %
# 160796 11 160796
cp dat_raw/adultbrainfull50_rna_outer_single_barcodes_dataset.mtx .

# adultbrainfull50_rna_outer_snareseq.mtx
# %%MatrixMarket matrix coordinate integer general
# %
# 10309 17271 8737719
head -n 3 dat_raw/adultbrainfull50_rna_outer_snareseq.mtx > adultbrainfull50_rna_outer_snareseq.mtx
sed '1,3d' dat_raw/adultbrainfull50_rna_outer_snareseq.mtx | awk '{if($2<=10000) print$0}' >> adultbrainfull50_rna_outer_snareseq.mtx
# 17271    -> 10000
# 8737719  -> 4970472


# adultbrainfull50_rna_outer_snareseq_barcodes.tsv  10310
# index	tissue	dev_stage	celltype	dataset	dataset_id	batch	Age	n_genes
# 09K_ACCCTCCGAAGC	brain	adult		SNARE-seq	SNARE-seq_brain_adult	0		325
cp dat_raw/adultbrainfull50_rna_outer_snareseq_barcodes.tsv .

# adultbrainfull50_rna_outer_snareseq_barcodes_dataset.mtx
# %%MatrixMarket matrix coordinate integer general
# %
# 10309 11 10309
cp dat_raw/adultbrainfull50_rna_outer_snareseq_barcodes_dataset.mtx .






#mtx format: first column (cell count) & second column (gene count)

## downsample unpaired atacseq data
sed '1,3d' mtx_raw/adultbrainfull50_atac_outer_single.mtx | awk '{if($1<101) print$0}' > adultbrainfull50_atac_outer_single.mtx  # ~45s
sed '1,3d' mtx_raw/adultbrainfull50_rna_outer_single.mtx | awk '{if($1<101) print$0}' > adultbrainfull50_rna_outer_single.mtx    # ~45s

## downsample paired rnaseq data
sed '1,3d' mtx_raw/adultbrainfull50_rna_outer_snareseq_barcodes_dataset.mtx | head -n 100 > adultbrainfull50_rna_outer_snareseq_barcodes_dataset.mtx
head -n 101 mtx_raw/adultbrainfull50_rna_outer_snareseq_barcodes.tsv > adultbrainfull50_rna_outer_snareseq_barcodes.tsv
sed '1,3d' mtx_raw/adultbrainfull50_rna_outer_snareseq.mtx | awk '{if($1<101) print$0}' > adultbrainfull50_rna_outer_snareseq.mtx



from datetime import datetime
print(datetime.now())

snare-seq rna: cell_num (10309)  gene_num (17271)

babel -> random???


time python ~/Polarbear/bin/run_polarbear.py --path_x adultbrainfull50_rna_outer_snareseq.mtx        \
                                             --path_y adultbrainfull50_atac_outer_snareseq.mtx       \
                                             --outdir output_semi_gpu                                \
                                             --patience 45                                           \
                                             --path_x_single nornasingle   \
                                             --path_y_single noatacsingle  \
                                             --train_test_split random                                \
                                             --train train --batch_size 1


time python ~/Polarbear/bin/run_polarbear.py --path_x adultbrainfull50_rna_outer_snareseq.mtx        \
                                             --path_y adultbrainfull50_atac_outer_snareseq.mtx       \
                                             --outdir output_semi_gpu                                \
                                             --patience 45                                           \
                                             --path_x_single adultbrainfull50_rna_outer_single.mtx   \
                                             --path_y_single adultbrainfull50_atac_outer_single.mtx  \
                                             --train_test_split random                                \
                                             --train train --batch_size 1

## time: 5 min/iter (batch_size: 256, gpu_num: 1)
python ~/Polarbear/bin/run_polarbear.py --path_x adultbrainfull50_rna_outer_snareseq.mtx        \
                                        --path_y adultbrainfull50_atac_outer_snareseq.mtx       \
                                        --outdir output_semi_gpu                                \
                                        --patience 45                                           \
                                        --path_x_single adultbrainfull50_rna_outer_single.mtx   \
                                        --path_y_single adultbrainfull50_atac_outer_single.mtx  \
                                        --train_test_split babel                                \
                                        --train train --batch_size 256                                          

## time: 5 min/iter... (batch_size: 512, gpu_num: 3)
python ~/Polarbear/bin/run_polarbear.py --path_x adultbrainfull50_rna_outer_snareseq.mtx        \
                                        --path_y adultbrainfull50_atac_outer_snareseq.mtx       \
                                        --outdir output_semi_gpu                                \
                                        --patience 45                                           \
                                        --path_x_single adultbrainfull50_rna_outer_single.mtx   \
                                        --path_y_single adultbrainfull50_atac_outer_single.mtx  \
                                        --train_test_split babel                                \
                                        --train train --batch_size 512 



## evaluation  ~8.5 min
python ~/Polarbear/bin/run_polarbear.py --path_x adultbrainfull50_rna_outer_snareseq.mtx        \
                                        --path_y adultbrainfull50_atac_outer_snareseq.mtx       \
                                        --outdir output_semi_gpu                                \
                                        --patience 45                                           \
                                        --path_x_single adultbrainfull50_rna_outer_single.mtx   \
                                        --path_y_single adultbrainfull50_atac_outer_single.mtx  \
                                        --train_test_split babel                                \
                                        --train predict --evaluate evaluate --batch_size 512

## output files
# *_stats_atac_auroc_auprnorm.txt (only focus on peaks in the Cell paper!!!)
# val_auc_peak
# val_auc_peak_flatten
# val_auprc_peak
# val_auprc_peak_flatten
# test_auc_peak
# test_auc_peak_flatten (!!!)
# test_auprc_peak
# test_auprc_peak_flatten

# *_stats_foscttm.txt (FOSCTTM score)
# val_av_fraction_rna
# val_av_fraction_atac
# test_av_fraction_rna
# test_av_fraction_atac

# *_stats_rna_cor.txt
# val_cor_gene
# val_cor_gene_flatten
# test_cor_gene
# test_cor_gene_flatten (!!!)

# *_test_atac_auc.txt
# *_test_atac_auprc.txt
# *_test_atac_npos.txt
# *_test_rna_cor.txt


## prediction  ~2 min
python ~/Polarbear/bin/run_polarbear.py --path_x adultbrainfull50_rna_outer_snareseq.mtx        \
                                        --path_y adultbrainfull50_atac_outer_snareseq.mtx       \
                                        --outdir output_semi_gpu                                \
                                        --patience 45                                           \
                                        --path_x_single adultbrainfull50_rna_outer_single.mtx   \
                                        --path_y_single adultbrainfull50_atac_outer_single.mtx  \
                                        --train_test_split babel                                \
                                        --train predict --predict predict --batch_size 512

# *_test_rnanorm_pred.txt & *_train_rnanorm_pred.txt
# ncell * ngenes

# should be information of test dataset (not train)
# *_train_atac_embedding_on_atacVAE.txt             (scATAC projection on scATAC bottleneck layer)
# *_train_rna_translatedembedding_on_atacVAE.txt    (scRNA projection on scATAC AE bottleneck layer)
# *_train_sorted_fraction_1to2_atacVAE.txt          (FOSCTTM score for each domain 1 cell query when mapping to domain 2)
# *_train_sorted_fraction_2to1_atacVAE.txt          (FOSCTTM score for each domain 2 cell query when mapping to domain 1)


## plot ROC curve for RNA > ATAC
# conda install matplotlib
# "evaluation_functions.py"  add "plot_auroc_perpeak_2" function
# mask "eval_atac_AUROC_AUPR" and "eval_rna_correlation" function in "run_polarbear.py"

## plot scatter for ATAC > RNA
# pip install mpl_scatter_density astropy
# "evaluation_functions.py"  add "plot_cor_pergene_2" function
# mask "eval_atac_AUROC_AUPR" and "eval_rna_correlation" function in "run_polarbear.py"



# show start and running time 
ps -eo pid,lstart,etime | grep 193551


#path_x: scRNA co-assay (SNARE-seq) file path   (https://noble.gs.washington.edu/~ranz0/Polarbear/data/adultbrainfull50_rna_outer_snareseq.mtx)
#path_y: scATAC co-assay (SNARE-seq) file path  (https://noble.gs.washington.edu/~ranz0/Polarbear/data/adultbrainfull50_atac_outer_snareseq.mtx)
#patience: patience for early stopping (default: 45)
#path_x_single: scRNA single-assay file path    (https://noble.gs.washington.edu/~ranz0/Polarbear/data/adultbrainfull50_rna_outer_single.mtx)
#path_y_single: scATAC single-assay file path   (https://noble.gs.washington.edu/~ranz0/Polarbear/data/adultbrainfull50_atac_outer_single.mtx)
#train_test_split：train/val/test split version, "random" or "babel" (default: 'random')
#train: "train": train the model from the beginning; "predict": load existing model for downstream prediction (default: predict)

#data dir: https://noble.gs.washington.edu/~ranz0/Polarbear/data/
#adultbrainfull50_atac_outer_peaks.txt	                       2021-12-09 23:34	5.1M	 
#adultbrainfull50_atac_outer_peaks_noXY_diffexp.txt	           2021-12-09 23:34	7.9M	 
#adultbrainfull50_atac_outer_single.mtx	                       2021-12-09 23:35	3.7G	 
#adultbrainfull50_atac_outer_single_barcodes.tsv	             2021-12-09 23:33	17M	 
#adultbrainfull50_atac_outer_single_barcodes_dataset.mtx	     2021-12-09 23:34	1.7M	 
#adultbrainfull50_atac_outer_snareseq.mtx	                     2021-12-09 23:34	267M	 
#adultbrainfull50_atac_outer_snareseq_barcodes.tsv	           2021-12-09 23:33	703K	 
#adultbrainfull50_atac_outer_snareseq_barcodes_dataset.mtx	   2021-12-09 23:34	90K	 
#adultbrainfull50_rna_outer_genes.txt	                         2021-12-09 23:35	112K	 
#adultbrainfull50_rna_outer_single.mtx	                       2021-12-09 23:34	2.9G	 
#adultbrainfull50_rna_outer_single_barcodes.tsv	               2021-12-09 23:34	15M	 
#adultbrainfull50_rna_outer_single_barcodes_dataset.mtx	       2021-12-09 23:35	1.6M	 
#adultbrainfull50_rna_outer_snareseq.mtx	                     2021-12-09 23:34	102M	 
#adultbrainfull50_rna_outer_snareseq_barcodes.tsv	             2021-12-09 23:34	698K	 
#adultbrainfull50_rna_outer_snareseq_barcodes_dataset.mtx	     2021-12-09 23:34	90K	 
#babel_genes.txt	                                             2021-12-09 23:34	219K	 
#babel_test_barcodes.txt	                                     2021-12-09 23:34	20K	 
#babel_train_barcodes.txt	                                     2021-12-09 23:34	128K	 
#babel_valid_barcodes.txt                                      2021-12-09 23:34	23K	 



######################## CMOT #############################
# https://github.com/daifengwanglab/CMOT/tree/51719ac5396889551027ce5436606e5fc06e30ec
conda create -n CMOT python=3.6.8
conda activate CMOT
conda install  pandas numpy scikit-learn
pip install pot

git clone https://github.com/daifengwanglab/CMOT

## modify run_cmot.py
# add "param_search = args.param_search"

## modify cmot_evaluations.py
# add "from sklearn.ensemble import IsolationForest"
# "poor_mapped_cell_percent = (len(np.argwhere(preds==-1).reshape(-1))/len(snpXTest))*100" -> "poor_mapped_cell_percent = (len(np.argwhere(preds==-1).reshape(-1))/len(preds))*100"

python3 run_cmot.py --sourceX ./data/Pan-Cancer/PanCancerX.csv --sourceY ./data/Pan-Cancer/PanCancerY.csv --targetY ./data/Pan-Cancer/PanCancerY_hat.csv \
                    --K 5 --d 10 --W ./data/Pan-Cancer/W.npy --hc 3 --reg_e 5e03 --reg_cl 1e00 --topFeat 150 --k 40          # ~7s

python3 cmot_evaluations.py --targetX_hat ./data/Pan-Cancer/PanCancerX_hat.csv --predX_hat ./results/Norm_ModalityXhat.csv   # ~2s

keep training datasets same!




















