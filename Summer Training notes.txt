#### Day 3 ####
## 感知机
二分类模型
训练感知机等价于使用批量大小为1的梯度下降
感知机不能拟合XOR函数，它只能产生线性分割面

## 多层感知机
sigmoid & Tanh & ReLU激活函数
Softmax回归加入隐藏层后即多层感知机
多隐藏层  超参数（隐藏层数 & 每层隐藏层的大小）

## 多层感知机代码实现
一层感知机理论上可以拟合任意函数
浅层网络比深层网络实践上更难训练
激活函数相比网络层数对训练结果的影响小
神经网络最好不要设计成动态性（可能涉及实际问题）

## 模型选择
训练误差 & 泛化误差
验证数据集（评估模型好坏） & 测试数据集（只用一次，不能用于调参）
K-折交叉验证（常用K=5或10）常于非大数据集

## 过拟合和欠拟合
模型容量（拟合各种函数的能力）
估计模型容量（参数个数 & 参数值的选择范围）
VC dimension（一个最大的数据集的大小）
支持N维输入的感知机的VC维是N+1
一些多层感知机的VC维O(Nlog2N)

## Q&A
SVM处理大数据集速度较慢，且参数不太敏感
深度学习不太使用k-折交叉验证
超参数搜索（推荐经验导向或随机）

## 论文精读GAN
Generative Adversarial Nets
networks -> nets
GAN是无监督学习
用有监督学习的损失函数做无监督学习
可以训练模型对训练数据和测试数据进行区分






